Models Improvment - Predictions as Features
Schedule refresh for models
###pip install schedule
#import sys

#sys.path.append("/past/the/path/you/copied/here")
import time
import threading
import schedule
from IPython.display import display, Javascript
#def run_notebook_code():
    ### Your notebook code to be executed every 24 hours
#    display(Javascript('IPython.notebook.execute_cell_range(IPython.notebook.get_selected_index()+1, IPython.notebook.ncells())'))

#def run_scheduler():
    ### Schedule the code to run every 24 hours
#    schedule.every(24).hours.do(run_notebook_code)

    ### Run the scheduler
#    while True:
#        schedule.run_pending()
#        time.sleep(1)

    ### Create a thread for the scheduler and start it
#scheduler_thread = threading.Thread(target=run_scheduler)
#scheduler_thread.daemon = True  # Daemonize the thread so it exits when the main thread exits
#scheduler_thread.start()
Import Packages
#pip install factor_analyzer
#pip install --upgrade numpy
#pip install --user numpy
#pip install statsmodels
import pandas as pd
import numpy as np

import scipy.stats as ss
import researchpy as rp
import scipy.stats as stats
import csv
import pandas as pd
import numpy as np

from scipy import stats
from scipy.stats import chisquare
from scipy.stats import chi2_contingency
from scipy.stats import f_oneway
from scipy.stats import kstest
from scipy.stats import ks_2samp
from scipy.stats import norm
from scipy.stats import iqr

from sklearn.linear_model import LinearRegression
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.model_selection import train_test_split
from sklearn import preprocessing
from sklearn.preprocessing import LabelEncoder
from sklearn.datasets import load_boston
from sklearn import linear_model

import matplotlib.pyplot as plt
plt.style.use('classic')
import seaborn as sns
plt.style.use('seaborn')
get_ipython().run_line_magic('matplotlib', 'inline')

#from ydata_profiling import ProfileReport
import statsmodels.api as sm
import statsmodels.formula.api as smf

import chart_studio
import re
import cv2

import missingno as msno
import warnings
warnings.filterwarnings("ignore")

import cloudinary
import cloudinary.uploader
import cloudinary.api

from statsmodels.stats.outliers_influence import variance_inflation_factor
from statsmodels.tools.tools import add_constant

#port csv
#mport pyodbc
#.read_sql_query

import researchpy as rp
import scipy.stats as stats


import pandas as pd
import numpy as np
import scipy.stats as ss
from math import log
#pd.set_option('display.max_rows', None, 'display.max_columns', None)
Load new data Sample
from datetime import datetime
import os
import pandas as pd

# Path to the folder
folder_path = rfolder_path = r'C:/Users/Knowl/Desktop/‏‏SADAC System Project/1Input/1Input Basic Files/1.1Project questionnaire'

# Get a list of all Excel files in the folder
excel_files = [f for f in os.listdir(folder_path) if f.endswith('.xlsx')]

# Extract dates from the file names and create a dictionary mapping files to dates
file_dates = {file: pd.to_datetime(file.split('_')[-1].split('.')[0], errors='coerce') for file in excel_files}

# Sort the files by date
sorted_files = sorted(file_dates.keys(), key=file_dates.get, reverse=True)

# Select the 350 most recent files
recent_files = sorted_files[:350]

# Initialize an empty DataFrame to store the loaded data
loaded_data = pd.DataFrame()

# Load data from the "Main" tab of the selected files
for file in recent_files:
    file_path = os.path.join(folder_path, file)
    df_main = pd.read_excel(file_path, sheet_name='Main')  # Load only from the "Main" tab
    loaded_data = pd.concat([loaded_data, df_main])

# Reset the index of the merged DataFrame
loaded_data.reset_index(drop=True, inplace=True)

# Save "Main" tab to dataframe
df_Main_tab = loaded_data.copy()

# Rename the first column to '#Parent'
df_Main_tab = df_Main_tab.rename(columns={df_Main_tab.columns[0]: '#Parent'})

#df_Main_tab.head()
import os
import pandas as pd

# Path to the folder
folder_path = rfolder_path = r'C:/Users/Knowl/Desktop/‏‏SADAC System Project/1Input/1Input Basic Files/1.1Project questionnaire'

# Get a list of all Excel files in the folder
excel_files = [f for f in os.listdir(folder_path) if f.endswith('.xlsx')]

# Extract dates from the file names and create a dictionary mapping files to dates
file_dates = {file: pd.to_datetime(file.split('_')[-1].split('.')[0], errors='coerce') for file in excel_files}

# Sort the files by date
sorted_files = sorted(file_dates.keys(), key=file_dates.get, reverse=True)

# Select the 350 most recent files
recent_files = sorted_files[:350]

# Initialize an empty DataFrame to store the loaded data from the specified tab
loaded_data_gIYUS4 = pd.DataFrame()

# Load data from the "Data.root.pAGE3.gIYUS4" tab of the selected files
for file in recent_files:
    file_path = os.path.join(folder_path, file)
    df_gIYUS4 = pd.read_excel(file_path, sheet_name='Data.root.pAGE3.gIYUS4')  # Load only from the specified tab
    loaded_data_gIYUS4 = pd.concat([loaded_data_gIYUS4, df_gIYUS4])

# Reset the index of the merged DataFrame
loaded_data_gIYUS4.reset_index(drop=True, inplace=True)

# Select only the first 6 categories for each participant
df_gIYUS4_tab_first_6 = loaded_data_gIYUS4.groupby('#Parent').head(6).copy()

# Create a new column for counting occurrences within each group
df_gIYUS4_tab_first_6['count'] = df_gIYUS4_tab_first_6.groupby('#Parent').cumcount()

# Pivot the table to create columns for each category
pivoted_gIYUS4_tab = df_gIYUS4_tab_first_6.pivot_table(index='#Parent', columns='dataText', values='count', aggfunc='count', fill_value=0)

# Reset the index to make #Parent a regular column
pivoted_gIYUS4_tab.reset_index(inplace=True)

# Display the transformed DataFrame
#pivoted_gIYUS4_tab.head()
import os
import pandas as pd

# Path to the folder
folder_path = rfolder_path = r'C:/Users/Knowl/Desktop/‏‏SADAC System Project/1Input/1Input Basic Files/1.1Project questionnaire'

# Get a list of all Excel files in the folder
excel_files = [f for f in os.listdir(folder_path) if f.endswith('.xlsx')]

# Extract dates from the file names and create a dictionary mapping files to dates
file_dates = {file: pd.to_datetime(file.split('_')[-1].split('.')[0], errors='coerce') for file in excel_files}

# Sort the files by date
sorted_files = sorted(file_dates.keys(), key=file_dates.get, reverse=True)

# Select the 350 most recent files
recent_files = sorted_files[:350]

# Initialize an empty DataFrame to store the loaded data from the specified tab
loaded_data_gIYUS3 = pd.DataFrame()

# Load data from the "Data.root.pAGE3.gIYUS3" tab of the selected files
for file in recent_files:
    file_path = os.path.join(folder_path, file)
    df_gIYUS3 = pd.read_excel(file_path, sheet_name='Data.root.pAGE3.gIYUS3')  # Load only from the specified tab
    loaded_data_gIYUS3 = pd.concat([loaded_data_gIYUS3, df_gIYUS3])

# Select only the first 6 categories for each participant
df_gIYUS3_tab_first_6 = loaded_data_gIYUS3.groupby('#Parent').head(6).copy()

# Create a new column for counting occurrences within each group
df_gIYUS3_tab_first_6['count'] = df_gIYUS3_tab_first_6.groupby('#Parent').cumcount()

# Pivot the table to create columns for each category
pivoted_gIYUS3_tab = df_gIYUS3_tab_first_6.pivot_table(index='#Parent', columns='dataText', values='count', aggfunc='count', fill_value=0)

# Reset the index to make #Parent a regular column
pivoted_gIYUS3_tab.reset_index(inplace=True)

# Display the transformed DataFrame
#pivoted_gIYUS3_tab.head()
# Assuming df_Main_tab, pivoted_gIYUS4_tab, and pivoted_gIYUS3_tab are your DataFrames
# If not, replace them with your actual DataFrame variables

# Merge df_Main_tab with pivoted_gIYUS4_tab based on #Parent
merged_df = pd.merge(df_Main_tab, pivoted_gIYUS4_tab, on='#Parent', how='left')

# Merge the result with pivoted_gIYUS3_tab based on #Parent
merged_df = pd.merge(merged_df, pivoted_gIYUS3_tab, on='#Parent', how='left')

#merged_df.head()
# Select columns that do not end with 'dataText'
filtered_columns = [col for col in merged_df.columns if not col.endswith('dataText')]

# Create a new DataFrame with the selected columns
filtered_dataframe = merged_df[filtered_columns]
# Assuming your DataFrame is named 'filtered_dataframe'
# Replace 'filtered_dataframe' with the actual name of your DataFrame

# List of columns to be dropped
columns_to_drop = [
    'ProcessInstance.BiztalkID',
    'ProcessInstance.FormID',
    'ProcessInstance.UserID',
    'ProcessInstance.PhaseID',
    'ProcessInstance.UpdateDate',
    'ProcessInstance.StageStatus',
    'ProcessInstance.FlowID',
    'Data.root.MetaData.referenceNumber',
    'Data.root.MetaData.sentDate',
    'Data.root.MetaData.processId',
    'Data.root.MetaData.language',
    'Data.root.pAGE3.gIYUS3',
    'Data.root.pAGE3.gIYUS4',
    'Data.root.Files',
    'Data.root.pAGE3.gIYUS10',
    'Data.root.pAGE3.gIYUS11',
    'Data.root.pAGE2.jOBB',
    'Data.root.pAGE2.aRMY4'
]

# Drop the specified columns
filtered_dataframe = filtered_dataframe.drop(columns=columns_to_drop, errors='ignore')
# Assuming filtered_dataframe is your DataFrame

column_mapping = {
    "ProcessInstance.CreationDate": "Date",
    "#Parent": "Index",
    "Data.root.pAGE2.aGE": "Age_Num",
    "Data.root.pAGE2.gender.dataCode": "Gender_Dico",
    "Data.root.pAGE2.familystatus.dataCode": "Married_Dico",
    "Data.root.pAGE2.nATIO.dataCode": "Nation_Dico",
    "Data.root.pAGE2.mIUT1.dataCode": "Minority_Dico",
    "Data.root.pAGE2.mIUT.dataCode": "Minority_Type_Categor",
    "Data.root.pAGE2.eDU.dataCode": "Current_Education_Categor",
    "Data.root.pAGE2.eDU2.dataCode": "Graduation_Average_Num",
    "Data.root.pAGE2.eDU3.dataCode": "Math_Units_Num",
    "Data.root.pAGE2.eDU4.dataCode": "English_Units_Num",
    "Data.root.pAGE2.eDU5.dataCode": "Bachelors_Degree_Average_Num",
    "Data.root.pAGE2.eDU6.dataCode": "Masters_Degree_Average_Num",
    "Data.root.pAGE2.eDU7.dataCode": "Relevant_Education_Dico",
    "Data.root.pAGE2.eDU8.dataCode": "Do_Psyc_Test_Dico",
    "Data.root.pAGE2.eDU9.dataCode": "Psyc_Test_Grade_Num",
    "Data.root.pAGE2.eDU10.dataCode": "Achievements_Preception_Num",
    "Data.root.pAGE2.eDU11.dataCode": "Hebrew_1_Expressive_Num",
    "Data.root.pAGE2.eDU12.dataCode": "Hebrew_2_Vocabulary_Num",
    "Data.root.pAGE2.eDU13.dataCode": "Hebrew_3_Writing_Num",
    "Data.root.pAGE2.eDU14.dataCode": "Hebrew_4_Reading_Num",
    "Data.root.pAGE2.eDU15.dataCode": "Hebrew_5_Proofreading_Num",
    "Data.root.pAGE2.eDU16.dataCode": "Psych_Tests_Subjective_Num",
    "Data.root.pAGE2.eDU17.dataCode": "Temper_Control_1_Num",
    "Data.root.pAGE2.eDU18.dataCode": "Temper_Control_2_Num",
    "Data.root.pAGE2.eDU19.dataCode": "Temper_Control_3_Num",
    "Data.root.pAGE2.eDU20.dataCode": "Temper_Control_4_Num",
    "Data.root.pAGE2.eDU21.dataCode": "Temper_Control_5_Num",
    "Data.root.pAGE2.aRMY1.dataCode": "Service_Type_Categor",
    "Data.root.pAGE2.aRMY.dataCode": "Commander_Army_Dico",
    "Data.root.pAGE2.aRMY2.dataCode": "Kazin_Army_Dico",
    "Data.root.pAGE2.aRMY3.dataCode": "Special_Unit_Army_Dico",
    "Data.root.pAGE2.aRMY5.dataCode": "Role_Type_Army_Categor",
    "Data.root.pAGE2.aRMY6.dataCode": "Kaba_Grade_Army_Num",
    "Data.root.pAGE2.aRMY7.dataCode": "Dapar_Grade_Army_Num",
    "Data.root.pAGE2.aRMY20.dataCode": "Mechina_Before_Army_Dico",
    "Data.root.pAGE2.aRMY21.dataCode": "Year_of_Service_Army_Dico",
    "Data.root.pAGE2.aRMY8.dataCode": "Army_Disciplinary_Dico",
    "Data.root.pAGE2.aRMY9.dataCode": "Conviction_Army_Dico",
    "Data.root.pAGE2.aRMY10.dataCode": "Arrest_Prison_Army_Dico",
    "Data.root.pAGE2.aRMY11.dataCode": "Mental_Treatment_Army_Dico",
    "Data.root.pAGE2.aRMY12.dataCode": "Mental_Release_Army_Dico",
    "Data.root.pAGE2.jOB.dataCode": "Relevant_Job_Experience_Dico",
    "Data.root.pAGE2.jOB2.dataCode": "Previous_Gius_Attempts_Dico",
    "Data.root.pAGE2.jOB3.dataCode": "Number_of_Attempts_Num",
    "Data.root.pAGE2.jOB4.dataCode": "Miun_Stop_Reason_Categor",
    "Data.root.pAGE2.jOB5.dataCode": "Past_Permanent_Officer_Dico",
    "Data.root.pAGE2.jOB6.dataCode": "Saham_Officer_Past_Dico",
    "Data.root.pAGE2.jOB7.dataCode": "Past_Layoffs_Dico",
    "Data.root.pAGE2.jOB8.dataCode": "Another_Job_Nomination_Dico",
    "Data.root.pAGE2.jOB9.dataCode": "Max_Procedure_Duration_Num",
    "Data.root.pAGE2.tAS1.dataCode": "Previous_Arrest_Dico",
    "Data.root.pAGE2.tAS2.dataCode": "Criminal_Record_Dico",
    "Data.root.pAGE2.tAS3.dataCode": "Conviction_in_Court_Dico",
    "Data.root.pAGE2.tAS4.dataCode": "Light_Drugs_Dico",
    "Data.root.pAGE2.tAS5.dataCode": "Light_Drugs_Last_Use_Num",
    "Data.root.pAGE2.tAS6.dataCode": "Hard_Drugs_Dico",
    "Data.root.pAGE2.tAS7.dataCode": "Hard_Drugs_Last_Use_Num",
    "Data.root.pAGE2.tAS8.dataCode": "Drinking_Alcohol_Frequ_Num",
    "Data.root.pAGE2.tAS9.dataCode": "Gambling_Frequ_Num",
    "Data.root.pAGE2.tAS10.dataCode": "Unemployment_Dico",
    "Data.root.pAGE2.tAS11.dataCode": "Financial_Difficulties_Dico",
    "Data.root.pAGE2.tAS12.dataCode": "Pshitat_Regel_Dico",
    "Data.root.pAGE2.tAS13.dataCode": "Debts_Dico",
    "Data.root.pAGE2.bRI.dataCode": "Physical_Fitness_Frequ_Num",
    "Data.root.pAGE2.bRI2": "Height_Num",
    "Data.root.pAGE2.bRI3": "Weight_Num",
    "Data.root.pAGE2.bRI4.dataCode": "Cigarettes_Dico",
    "Data.root.pAGE2.bRI5.dataCode": "Cigarettes_Num",
    "Data.root.pAGE2.bRI6.dataCode": "Chronic_Disease_Dico",
    "Data.root.pAGE2.bRI7.dataCode": "Physical_Limitations_Dico",
    "Data.root.pAGE2.bRI8.dataCode": "Mental_Difficulties_Dico",
    "Data.root.pAGE2.bRI9.dataCode": "Psychiatric_Drugs_Dico",
    "Data.root.pAGE3.gIYUS1.dataCode": "Volunteering_Dico",
    "Data.root.pAGE3.gIYUS12.dataCode": "Volunteering_Scope_Num",
    "Data.root.pAGE3.gIYUS.dataCode": "Service_Period_Commitment_Dico",
    "Data.root.pAGE3.gIYUS2.dataCode": "Work_Perceived_Maching_Num",
    "Data.root.pAGE3.gIYUS5.dataCode": "Previous_Job_Salary_Num",
    "Data.root.pAGE3.gIYUS6.dataCode": "Salary_Expectations_Num",
    "ProcessInstance.ReferenceNumber": "Index_Real",
    "Data.root.pAGE2.mAIL": "Mail",
    "Data.root.pAGE2.iD": "ID_Num",
    "Data.root.pAGE2.lN": "First_Name",
    "Data.root.pAGE2.fN": "Last_Name",
    "ספורט":"Sport",
    "בריאות":"Healt",
    "בישול":"Cooking",
    "פעילות התנדבותית":"Volunteering",
    "פסיכולוגיה":"Psychology",
    "ספרות":"Literature",
    "פוליטיקה":"Politics",
    "קולנוע":"Theater",
    "ניהול אורח חיים בריא":"Managing_Healthy_Lifestyle",
    "גלישה באינטרנט":"Web_Surfing",
    "הימורים":"Gambling",
    "טבע וטיולים":"Nature_and_Trips",
    "טכנולוגיה ומחשבים":"Technology_and_Computers",
    "כלכלה":"Economy",
    "מדע":"Science",
    "מפגשים עם חברים":"Meeting_With_Friends",
    "בילויים במסיבות / ברים":"Enjoy_Parties_Bars",
    "אקטואליה":"Actuavlia",
    "אומנות":"Art",
    "כלי נשק":"Weapons",
    "פעילות מיסטית":"Mistic_Activity",
    "מוזיקה":"Music",
    "ספורט אתגרי":"Extreme_Sports",
    "אפשרות לנהל ולפקד":"Manage_and_Command",
    "האתגר והעניין בעבודה":"Challenging_Interesting_Work",
    "תנאים סוציאליים ורווחה":"Social_Benefits",
    "רצון להעניק סיוע לאזרחים":"Assistance_to_Citizens",
    "אפשרות להתפתחות מקצועית ואישית":"Personal_Development",
    "תרומת עבודת השוטר לחברה":"Contribution_to_Society",
    "המלצה של המשפחה/חברים":"Recommendation",
    "יציבות תעסוקתית":"Employment_Stability",
    "השכר":"Good_Salary",
    "אפשרות להילחם בפשיעה":"Crime_Fighting",
    "אינטראקציה עם אנשים":"Interaction_With_People",
    "הגיוון בעבודה":"Diversity_at_Work",
    "מיקום נוח של יחידת השירות":"Convenient_Work_Location",
    "ברירת מחדל":"Default_Employment",
    "אפשרות ללבוש מדים":"Wearing_Uniform",
    "האפשרות להפעיל כוח במסגרת התפקיד":"Use_Force",
    "היכולת להפעיל סמכות":"Exercise_Authority",
    "התדמית המכובדת של העבודה":"Respectable_Job",
    "שעות עבודה נוחות":"Convenient_Working_Hours",
    "תפקיד המאפשר עצמאות ואוטונומיה":"Independence_and_Autonomy",
    
}

filtered_dataframe.rename(columns=column_mapping, inplace=True)
# Get the current column names
column_names = filtered_dataframe.columns.tolist()

# Update the name of the 6th column from the right
column_names[-6] = "The_Action_In_Work"

# Assign the updated column names back to the DataFrame
filtered_dataframe.columns = column_names
# Assuming filtered_dataframe is your DataFrame

# Replace values in the "Married_Dico" column
replacement_dict = {"widower": "0", "Single": "0", "divorcee": "0", "Married": "1"}
filtered_dataframe["Married_Dico"].replace(replacement_dict, inplace=True)
import pandas as pd

# Assuming your DataFrame is named filtered_dataframe
# Identify columns ending with "Dico" and replace 2 with 0
dico_columns = [col for col in filtered_dataframe.columns if col.endswith("Dico")]

# Replace 2 with 0 in identified columns
filtered_dataframe[dico_columns] = filtered_dataframe[dico_columns].replace(2, 0)
import pandas as pd

# Assuming your DataFrame is named filtered_dataframe
# Check for columns with words starting with a lowercase letter
selected_columns = filtered_dataframe.columns[filtered_dataframe.columns.str.contains(r'\b[a-z]', regex=True)]
Handling missing values
df = pd.DataFrame(filtered_dataframe)
# Assuming df_train is your data frame
df = df.drop_duplicates(subset='ID_Num')
df["Number_of_Attempts_Num"].fillna(0, inplace=True)
import pandas as pd

# Create a new variable "Masters_Degree_Average_up_84" based on conditions

df["Masters_Degree_Average_up_84_Dico"] = 0  # Default value is set to 0

# Update values based on conditions
df.loc[df["Masters_Degree_Average_Num"].between(9, 12, inclusive=True), "Masters_Degree_Average_up_84_Dico"] = 1
import pandas as pd

# Assuming your DataFrame is named df
# Create a new variable "Psyc_Test_600_Up" based on conditions
df["Psyc_Test_600_Up_Dico"] = 0  # Default value is set to 0

# Update values based on conditions
df.loc[df["Psyc_Test_Grade_Num"].between(9, 12, inclusive=True), "Psyc_Test_600_Up_Dico"] = 1
# Assuming your DataFrame is named df
# Create a new variable "Psyc_Test_600_Up" based on conditions
df["Psyc_Test_450_600_Dico"] = 0  # Default value is set to 0

# Update values based on conditions
df.loc[df["Psyc_Test_Grade_Num"].between(6, 8, inclusive=True), "Psyc_Test_450_600_Dico"] = 1
# Assuming your DataFrame is named df
# Create a new variable "Psyc_Test_600_Up" based on conditions
df["Psyc_Test_450_Less_Dico"] = 0  # Default value is set to 0

# Update values based on conditions
df.loc[df["Psyc_Test_Grade_Num"].between(1, 5, inclusive=True), "Psyc_Test_450_Less_Dico"] = 1
# Assuming your DataFrame is named df
# Create a new variable "Psyc_Test_600_Up" based on conditions
df["Kaba_Grade_55_UP_Dico"] = 0  # Default value is set to 0

# Update values based on conditions
df.loc[df["Kaba_Grade_Army_Num"].between(15, 17, inclusive=True), "Kaba_Grade_55_UP_Dico"] = 1
# Assuming your DataFrame is named df
# Create a new variable "Psyc_Test_600_Up" based on conditions
df["Kaba_Grade_51_54_Dico"] = 0  # Default value is set to 0

# Update values based on conditions
df.loc[df["Kaba_Grade_Army_Num"].between(12, 14, inclusive=True), "Kaba_Grade_51_54_Dico"] = 1
# Assuming your DataFrame is named df
# Create a new variable "Psyc_Test_600_Up" based on conditions
df["Kaba_Grade_46_Less_Dico"] = 0  # Default value is set to 0

# Update values based on conditions
df.loc[df["Kaba_Grade_Army_Num"].between(1, 6, inclusive=True), "Kaba_Grade_46_Less_Dico"] = 1
# Assuming your DataFrame is named df
# Create a new variable "Psyc_Test_600_Up" based on conditions
df["Kaba_Grade_51_Up_Dico"] = 0  # Default value is set to 0

# Update values based on conditions
df.loc[df["Kaba_Grade_Army_Num"].between(12, 17, inclusive=True), "Kaba_Grade_51_Up_Dico"] = 1

# Assuming your DataFrame is named df
# Create a new variable "Psyc_Test_600_Up" based on conditions
df["Dapar_Grade_7_Up_Dico"] = 0  # Default value is set to 0

# Update values based on conditions
df.loc[df["Dapar_Grade_Army_Num"].between(8, 10, inclusive=True), "Dapar_Grade_7_Up_Dico"] = 1
# Assuming your DataFrame is named df
# Create a new variable "Psyc_Test_600_Up" based on conditions
df["Dapar_Grade_3_Less_Dico"] = 0  # Default value is set to 0

# Update values based on conditions
df.loc[df["Dapar_Grade_Army_Num"].between(2, 4, inclusive=True), "Dapar_Grade_3_Less_Dico"] = 1

# Assuming your DataFrame is named df
# Create a new variable "Psyc_Test_600_Up" based on conditions
df["Light_Drugs_Last_Year_Dico"] = 0  # Default value is set to 0

# Update values based on conditions
df.loc[df["Light_Drugs_Last_Use_Num"].between(1, 1, inclusive=True), "Light_Drugs_Last_Year_Dico"] = 1
# Assuming your DataFrame is named df
# Create a new variable "Psyc_Test_600_Up" based on conditions
df["Graduation_Average_60_Less_Dico"] = 0  # Default value is set to 0

# Update values based on conditions
df.loc[df["Graduation_Average_Num"].between(2, 5, inclusive=True), "Graduation_Average_60_Less_Dico"] = 1
# Assuming your DataFrame is named df
# Create a new variable "Psyc_Test_600_Up" based on conditions
df["Graduation_Average_85_Up_Dico"] = 0  # Default value is set to 0

# Update values based on conditions
df.loc[df["Graduation_Average_Num"].between(9, 11, inclusive=True), "Graduation_Average_85_Up_Dico"] = 1

# Assuming your DataFrame is named df
# Create a new variable "Psyc_Test_600_Up" based on conditions
df["English_4_5_Units_Num_Dico"] = 0  # Default value is set to 0

# Update values based on conditions
df.loc[df["English_Units_Num"].between(3, 4, inclusive=True), "English_4_5_Units_Num_Dico"] = 1
# Assuming your DataFrame is named df
# Create a new variable "Psyc_Test_600_Up" based on conditions
df["English_3_Units_Num_Dico"] = 0  # Default value is set to 0

# Update values based on conditions
df.loc[df["English_Units_Num"].between(2, 2, inclusive=True), "English_3_Units_Num_Dico"] = 1

# Assuming your DataFrame is named df
# Create a new variable "Psyc_Test_600_Up" based on conditions
df["Math_4_5_Units_Num_Dico"] = 0  # Default value is set to 0

# Update values based on conditions
df.loc[df["Math_Units_Num"].between(3, 4, inclusive=True), "Math_4_5_Units_Num_Dico"] = 1
# Assuming your DataFrame is named df
# Create a new variable "Psyc_Test_600_Up" based on conditions
df["Math_3_Units_Num_Dico"] = 0  # Default value is set to 0

# Update values based on conditions
df.loc[df["Math_Units_Num"].between(2, 2, inclusive=True), "Math_3_Units_Num_Dico"] = 1

# Assuming your DataFrame is named df
# Create a new variable "Psyc_Test_600_Up" based on conditions
df["Volunteering_3_Up_Week_Dico"] = 0  # Default value is set to 0

# Update values based on conditions
df.loc[df["Volunteering_Scope_Num"].between(4, 6, inclusive=True), "Volunteering_3_Up_Week_Dico"] = 1
# Assuming your DataFrame is named df
# Create a new variable "Psyc_Test_600_Up" based on conditions
df["Cigarettes_11_Up_Dico"] = 0  # Default value is set to 0

# Update values based on conditions
df.loc[df["Cigarettes_Num"].between(3, 4, inclusive=True), "Cigarettes_11_Up_Dico"] = 1

# Assuming your DataFrame is named df
# Create a new variable "Psyc_Test_600_Up" based on conditions
df["Academic_Education_Dico"] = 0  # Default value is set to 0

# Update values based on conditions
df.loc[df["Current_Education_Categor"].between(3, 6, inclusive=True), "Academic_Education_Dico"] = 1
# Assuming your DataFrame is named df
# Create a new variable "Psyc_Test_600_Up" based on conditions
df["No_Bagrut_Dico"] = 0  # Default value is set to 0

# Update values based on conditions
df.loc[df["Current_Education_Categor"].between(1, 1, inclusive=True), "No_Bagrut_Dico"] = 1
# Assuming your DataFrame is named df
# Create a new variable "Psyc_Test_600_Up" based on conditions
df["Arab_Muslim_Cristian"] = 0  # Default value is set to 0

# Update values based on conditions
df.loc[df["Minority_Type_Categor"].between(4, 5, inclusive=True), "Arab_Muslim_Cristian"] = 1
# Assuming your DataFrame is named df
# Create a new variable "Psyc_Test_600_Up" based on conditions
df["Prisha_Yezoma_on_Last_Attempt_Dico"] = 0  # Default value is set to 0

# Update values based on conditions
df.loc[df["Miun_Stop_Reason_Categor"].between(7, 7, inclusive=True), "Prisha_Yezoma_on_Last_Attempt_Dico"] = 1
# Assuming your DataFrame is named df
# Create a new variable "Psyc_Test_600_Up" based on conditions
df["Evaluation_Center_Filed_Last_Attempt_Dico"] = 0  # Default value is set to 0

# Update values based on conditions
df.loc[df["Miun_Stop_Reason_Categor"].between(2, 2, inclusive=True), "Evaluation_Center_Filed_Last_Attempt_Dico"] = 1
# Assuming your DataFrame is named df
# Create a new variable "Psyc_Test_600_Up" based on conditions
df["Dapar_Hebrew_Failurer_Last_Attempt_Dico"] = 0  # Default value is set to 0

# Update values based on conditions
df.loc[df["Miun_Stop_Reason_Categor"].between(1, 1, inclusive=True), "Dapar_Hebrew_Failurer_Last_Attempt_Dico"] = 1
# Assuming your DataFrame is named df
# Create a new variable "Psyc_Test_600_Up" based on conditions
df["Sacham_officer_Dico"] = 0  # Default value is set to 0

# Update values based on conditions
df.loc[df["Service_Type_Categor"].between(2, 2, inclusive=True), "Sacham_officer_Dico"] = 1
# Assuming your DataFrame is named df
# Create a new variable "Psyc_Test_600_Up" based on conditions
df["Combat_Service_Army_Dico"] = 0  # Default value is set to 0

# Update values based on conditions
df.loc[df["Role_Type_Army_Categor"].between(1, 1, inclusive=True), "Combat_Service_Army_Dico"] = 1
# List of variables
variable_list = {"Date", "Index", "ID_Num", "First_Name", "Last_Name", "Gender_Dico", "Married_Dico", "Nation_Dico", "Minority_Dico", "Relevant_Job_Experience_Dico", "Previous_Gius_Attempts_Dico", "Past_Permanent_Officer_Dico", "Saham_Officer_Past_Dico", "Past_Layoffs_Dico", "Another_Job_Nomination_Dico", "Previous_Arrest_Dico", "Criminal_Record_Dico", "Conviction_in_Court_Dico", "Light_Drugs_Dico", "Hard_Drugs_Dico", "Unemployment_Dico", "Financial_Difficulties_Dico", "Pshitat_Regel_Dico", "Debts_Dico", "Cigarettes_Dico", "Chronic_Disease_Dico", "Physical_Limitations_Dico", "Mental_Difficulties_Dico", "Psychiatric_Drugs_Dico", "Volunteering_Dico", "Service_Period_Commitment_Dico", "Do_Psyc_Test_Dico", "Relevant_Education_Dico", "Commander_Army_Dico", "Kazin_Army_Dico", "Special_Unit_Army_Dico", "Mechina_Before_Army_Dico", "Year_of_Service_Army_Dico", "Army_Disciplinary_Dico", "Conviction_Army_Dico", "Arrest_Prison_Army_Dico", "Mental_Treatment_Army_Dico", "Mental_Release_Army_Dico", "Age_Num", "Achievements_Preception_Num", "Hebrew_1_Expressive_Num", "Hebrew_2_Vocabulary_Num", "Hebrew_3_Writing_Num", "Hebrew_4_Reading_Num", "Hebrew_5_Proofreading_Num", "Psych_Tests_Subjective_Num", "Temper_Control_1_Num", "Temper_Control_2_Num", "Temper_Control_3_Num", "Temper_Control_4_Num", "Temper_Control_5_Num", "Max_Procedure_Duration_Num", "Drinking_Alcohol_Frequ_Num", "Gambling_Frequ_Num", "Physical_Fitness_Frequ_Num", "Height_Num", "Weight_Num", "Work_Perceived_Maching_Num", "Previous_Job_Salary_Num", "Salary_Expectations_Num", "Number_of_Attempts_Num", "Masters_Degree_Average_up_84_Dico", "Psyc_Test_600_Up_Dico", "Psyc_Test_450_600_Dico", "Psyc_Test_450_Less_Dico", "Kaba_Grade_55_UP_Dico", "Kaba_Grade_51_54_Dico", "Kaba_Grade_46_Less_Dico", "Dapar_Grade_7_Up_Dico", "Dapar_Grade_3_Less_Dico", "Light_Drugs_Last_Year_Dico", "Graduation_Average_60_Less_Dico", "Graduation_Average_85_Up_Dico", "English_4_5_Units_Num_Dico", "English_3_Units_Num_Dico", "Math_4_5_Units_Num_Dico", "Math_3_Units_Num_Dico", "Volunteering_3_Up_Week_Dico", "Cigarettes_11_Up_Dico", "Academic_Education_Dico", "No_Bagrut_Dico", "Arab_Muslim_Cristian", "Sacham_officer_Dico", "Combat_Service_Army_Dico", "Prisha_Yezoma_on_Last_Attempt_Dico", "Evaluation_Center_Filed_Last_Attempt_Dico", "Dapar_Hebrew_Failurer_Last_Attempt_Dico", "Role_Type_Army_Categor", "Service_Type_Categor", "Miun_Stop_Reason_Categor", "Minority_Type_Categor", "Current_Education_Categor", "Graduation_Average_Num", "Math_Units_Num", "English_Units_Num", "Bachelors_Degree_Average_Num", "Volunteering_Scope_Num", "Cigarettes_Num", "Hard_Drugs_Last_Use_Num", "Light_Drugs_Last_Use_Num", "Dapar_Grade_Army_Num", "Kaba_Grade_Army_Num", "Psyc_Test_Grade_Num", "Masters_Degree_Average_Num", "Mail"}

# Check variables that do not exist in df
missing_variables = variable_list - set(df.columns)
print("Variables that do not exist in df:", missing_variables)

# Check variables in df that do not appear in the list
extra_variables = set(df.columns) - variable_list
print("Variables in df that do not appear in the list:", extra_variables)
Variables that do not exist in df: set()
Variables in df that do not appear in the list: {'Enjoy_Parties_Bars', 'Employment_Stability', 'Diversity_at_Work', 'Managing_Healthy_Lifestyle', 'Nature_and_Trips', 'Economy', 'Convenient_Working_Hours', 'Interaction_With_People', 'Default_Employment', 'Healt', 'Cooking', 'Music', 'Exercise_Authority', 'Psychology', 'Recommendation', 'Respectable_Job', 'Technology_and_Computers', 'Crime_Fighting', 'Volunteering', 'Web_Surfing', 'Contribution_to_Society', 'The_Action_In_Work', 'Manage_and_Command', 'Art', 'Meeting_With_Friends', 'Theater', 'Gambling', 'Literature', 'Politics', 'Challenging_Interesting_Work', 'Assistance_to_Citizens', 'Index_Real', 'Actuavlia', 'Use_Force', 'Social_Benefits', 'Science', 'Convenient_Work_Location', 'Sport', 'Personal_Development', 'Extreme_Sports', 'Wearing_Uniform', 'Independence_and_Autonomy', 'Kaba_Grade_51_Up_Dico', 'Good_Salary'}
# List of variables in the desired order
desired_order = ["Date", "Index", "Index_Real", "ID_Num", "First_Name", "Last_Name", "Mail", "Gender_Dico", "Married_Dico", "Nation_Dico", "Minority_Dico", "Relevant_Job_Experience_Dico", "Previous_Gius_Attempts_Dico", "Past_Permanent_Officer_Dico", "Saham_Officer_Past_Dico", "Past_Layoffs_Dico", "Another_Job_Nomination_Dico", "Previous_Arrest_Dico", "Criminal_Record_Dico", "Conviction_in_Court_Dico", "Light_Drugs_Dico", "Hard_Drugs_Dico", "Unemployment_Dico", "Financial_Difficulties_Dico", "Pshitat_Regel_Dico", "Debts_Dico", "Cigarettes_Dico", "Chronic_Disease_Dico", "Physical_Limitations_Dico", "Mental_Difficulties_Dico", "Psychiatric_Drugs_Dico", "Volunteering_Dico", "Service_Period_Commitment_Dico", "Do_Psyc_Test_Dico", "Relevant_Education_Dico", "Commander_Army_Dico", "Kazin_Army_Dico", "Special_Unit_Army_Dico", "Mechina_Before_Army_Dico", "Year_of_Service_Army_Dico", "Army_Disciplinary_Dico", "Conviction_Army_Dico", "Arrest_Prison_Army_Dico", "Mental_Treatment_Army_Dico", "Mental_Release_Army_Dico", "Age_Num", "Achievements_Preception_Num", "Hebrew_1_Expressive_Num", "Hebrew_2_Vocabulary_Num", "Hebrew_3_Writing_Num", "Hebrew_4_Reading_Num", "Hebrew_5_Proofreading_Num", "Psych_Tests_Subjective_Num", "Temper_Control_1_Num", "Temper_Control_2_Num", "Temper_Control_3_Num", "Temper_Control_4_Num", "Temper_Control_5_Num", "Max_Procedure_Duration_Num", "Drinking_Alcohol_Frequ_Num", "Gambling_Frequ_Num", "Physical_Fitness_Frequ_Num", "Height_Num", "Weight_Num", "Work_Perceived_Maching_Num", "Previous_Job_Salary_Num", "Salary_Expectations_Num", "Number_of_Attempts_Num", "Masters_Degree_Average_up_84_Dico", "Psyc_Test_600_Up_Dico", "Psyc_Test_450_600_Dico", "Psyc_Test_450_Less_Dico", "Kaba_Grade_55_UP_Dico", "Kaba_Grade_51_54_Dico", "Kaba_Grade_46_Less_Dico", "Kaba_Grade_51_Up_Dico", "Dapar_Grade_7_Up_Dico", "Dapar_Grade_3_Less_Dico", "Light_Drugs_Last_Year_Dico", "Graduation_Average_60_Less_Dico", "Graduation_Average_85_Up_Dico", "English_4_5_Units_Num_Dico", "English_3_Units_Num_Dico", "Math_4_5_Units_Num_Dico", "Math_3_Units_Num_Dico", "Volunteering_3_Up_Week_Dico", "Cigarettes_11_Up_Dico", "Academic_Education_Dico", "No_Bagrut_Dico", "Arab_Muslim_Cristian", "Sacham_officer_Dico", "Combat_Service_Army_Dico", "Prisha_Yezoma_on_Last_Attempt_Dico", "Evaluation_Center_Filed_Last_Attempt_Dico", "Dapar_Hebrew_Failurer_Last_Attempt_Dico", 'Healt', 'Crime_Fighting', 'Convenient_Working_Hours', 'The_Action_In_Work', 'Music', 'Use_Force', 'Default_Employment', 'Psychology', 'Diversity_at_Work', 'Manage_and_Command', 'Sport', 'Art', 'Extreme_Sports', 'Meeting_With_Friends', 'Contribution_to_Society', 'Web_Surfing', 'Economy', 'Assistance_to_Citizens', 'Independence_and_Autonomy', 'Recommendation', 'Wearing_Uniform', 'Challenging_Interesting_Work', 'Volunteering', 'Actuavlia', 'Cooking', 'Enjoy_Parties_Bars', 'Personal_Development', 'Employment_Stability', 'Science', 'Nature_and_Trips', 'Good_Salary', 'Politics', 'Managing_Healthy_Lifestyle', 'Convenient_Work_Location', 'Gambling', 'Literature', 'Respectable_Job', 'Exercise_Authority', 'Technology_and_Computers', 'Interaction_With_People', 'Theater', 'Social_Benefits', "Role_Type_Army_Categor", "Service_Type_Categor", "Miun_Stop_Reason_Categor", "Minority_Type_Categor", "Current_Education_Categor", "Graduation_Average_Num", "Math_Units_Num", "English_Units_Num", "Bachelors_Degree_Average_Num", "Volunteering_Scope_Num", "Cigarettes_Num", "Hard_Drugs_Last_Use_Num", "Light_Drugs_Last_Use_Num", "Dapar_Grade_Army_Num", "Kaba_Grade_Army_Num", "Psyc_Test_Grade_Num", "Masters_Degree_Average_Num"]

# Reorder columns in df
df = df[desired_order]
df.head()
               Date  Index  Index_Real     ID_Num First_Name Last_Name  \
0  21/08/2023 14:44      1        5439   37107588          *         *   
1  17/08/2023 09:37      2        5403  211968169          *         *   
2  17/08/2023 07:43      3        5395  340866375          *         *   
3  17/08/2023 07:34      4        5391  206253106          *         *   
4  17/08/2023 07:45      5        5398  310274717          *         *   

                        Mail  Gender_Dico Married_Dico  Nation_Dico  ...  \
0  Roei.zami@mail.huji.ac.il          1.0            1            1  ...   
1     Adimarko6309@gmail.com          1.0            0            1  ...   
2       ntordjman3@gmail.com          1.0            1            1  ...   
3       Yardenza26@gmail.com          1.0            0            1  ...   
4      basalov1710@yahoo.com          1.0            1            1  ...   

   English_Units_Num  Bachelors_Degree_Average_Num  Volunteering_Scope_Num  \
0                4.0                          10.0                     NaN   
1                NaN                           NaN                     NaN   
2                2.0                           NaN                     NaN   
3                NaN                           NaN                     NaN   
4                NaN                           NaN                     NaN   

   Cigarettes_Num  Hard_Drugs_Last_Use_Num  Light_Drugs_Last_Use_Num  \
0             NaN                      NaN                       NaN   
1             NaN                      NaN                       NaN   
2             NaN                      NaN                       NaN   
3             NaN                      NaN                       1.0   
4             NaN                      NaN                       NaN   

   Dapar_Grade_Army_Num  Kaba_Grade_Army_Num  Psyc_Test_Grade_Num  \
0                   9.0                 15.0                  NaN   
1                   7.0                 15.0                 10.0   
2                   1.0                  1.0                  NaN   
3                   7.0                  9.0                  NaN   
4                   1.0                  1.0                  4.0   

   Masters_Degree_Average_Num  
0                        11.0  
1                         NaN  
2                         NaN  
3                         NaN  
4                         NaN  

[5 rows x 154 columns]
# Identify columns ending with '_Dico'
dico_columns = [col for col in df.columns if col.endswith('_Dico')]

# Replace missing values with 0 in _Dico columns
df[dico_columns] = df[dico_columns].fillna(0)
# Identify columns ending with '_Num'
num_columns = [col for col in df.columns if col.endswith('_Num')]

# Replace missing values with the mean in _Num columns
df[num_columns] = df[num_columns].fillna(df[num_columns].mean())

# Display the modified data frame
#print(df)
# Identify columns ending with '_Categor'
Categor_columns = [col for col in df.columns if col.endswith('_Categor')]

# Replace missing values with 999 in Categor columns
df[Categor_columns] = df[Categor_columns].fillna(999)
# Check for missing values in each column of df
missing_values = df.isnull().sum()

# Extract variables with missing values
variables_with_missing_values = missing_values[missing_values > 0]
# List of variables for which to calculate the average
expressive_variables = [
    'Hebrew_1_Expressive_Num',
    'Hebrew_2_Vocabulary_Num',
    'Hebrew_3_Writing_Num',
    'Hebrew_4_Reading_Num',
    'Hebrew_5_Proofreading_Num'
]

# Create a new column 'Hebrew_Meam_Num' containing the average of the specified variables
df['Hebrew_Meam_Num'] = df[expressive_variables].mean(axis=1)

# Display the modified data frame
#print(df)
# List of variables for which to calculate the average
Temp_variables = [
    'Temper_Control_1_Num',
    'Temper_Control_2_Num',
    'Temper_Control_3_Num',
    'Temper_Control_4_Num',
    'Temper_Control_5_Num'
]

# Create a new column 'Temp_Mean_Num' containing the average of the specified variables
df['Temp_Mean_Num'] = df[Temp_variables].mean(axis=1)

# Display the modified data frame
#print(df)
# Set the minimum and maximum limits
min_limit = 100
max_limit = 220

# Replace values outside the specified range with 173
df['Height_Num'] = df['Height_Num'].apply(lambda x: 173 if x < min_limit or x > max_limit else x)

# Display the modified data frame
#print(df)
# Set the minimum and maximum limits
min_limit = 30
max_limit = 150

# Replace values outside the specified range with 73
df['Weight_Num'] = df['Weight_Num'].apply(lambda x: 73 if x < min_limit or x > max_limit else x)

# Display the modified data frame
#print(df)
# Set the minimum and maximum limits
min_limit = 18
max_limit = 65

# Replace values outside the specified range with 27
df['Age_Num'] = df['Age_Num'].apply(lambda x: 27 if x < min_limit or x > max_limit else x)

# Display the modified data frame
#print(df)
df['BMI_Num'] = df.Weight_Num / (df.Height_Num * df.Height_Num / 10000)
# Set the minimum and maximum limits
min_limit = 15
max_limit = 50

# Replace values outside the specified range with 50
df['BMI_Num'] = df['BMI_Num'].apply(lambda x: 50 if x > max_limit else max(min(x, max_limit), min_limit))
# Set the thresholds for different BMI categories
underweight_threshold = 18.5
normal_threshold = 24.9999999
overweight_threshold = 29.9999999

# Create new dichotomous variables
df['Underweight_BMI_Dumi'] = (df['BMI_Num'] <= underweight_threshold).astype(int)
df['Normal_BMI_Dumi'] = ((df['BMI_Num'] >= underweight_threshold) & (df['BMI_Num'] <= normal_threshold)).astype(int)
df['Overweight_BMI_Dumi'] = ((df['BMI_Num'] >= normal_threshold) & (df['BMI_Num'] <= overweight_threshold)).astype(int)
df['Obesity_BMI_Dumi'] = (df['BMI_Num'] >= overweight_threshold).astype(int)

# Display the modified data frame
#print(df)
Feature Engineering & Enrichment
---- Gibushon Final Grade ----
Education_and_Inteligence_Index - Combine Variable
df['Dapar_Grade_3_Less_Dico_Rotated'] = df['Dapar_Grade_3_Less_Dico'] ^ 1
df['Education_and_Inteligence_Index'] = df.Dapar_Grade_3_Less_Dico_Rotated + df.Academic_Education_Dico + df.Graduation_Average_85_Up_Dico + df.Graduation_Average_60_Less_Dico
Volunteering_Dico_Index - Combine Variable
df['Volunteering_Dico_Index'] = df.Volunteering_Dico + (df.Volunteering_3_Up_Week_Dico * 2)
Psyc_Test_Index - Combine Variable
df['All_One'] = 1
df['Psyc_Test_Index'] = df.All_One - df.Psyc_Test_450_Less_Dico + (df.Psyc_Test_450_600_Dico * 1) + (df.Psyc_Test_600_Up_Dico * 2)
Job_Motivators_Index - Combine Variable
Job_Motivators_Corr = pd.DataFrame(df, columns=["Use_Force", "Independence_and_Autonomy", "Wearing_Uniform", "Social_Benefits","Exercise_Authority", "Default_Employment", "Respectable_Job", "Good_Salary", "Convenient_Working_Hours", "Personal_Development", "Contribution_to_Society", "Challenging_Interesting_Work", "Crime_Fighting", "Evaluation_Center_Target"])
df['Job_Motivators_Index'] = df.Use_Force *-0.0486 + df.Independence_and_Autonomy * -0.160562 + df.Wearing_Uniform *-0.174265 + df.Social_Benefits * -0.089402 + df.Exercise_Authority * -0.109815 + df.Default_Employment * -0.128360 + df.Respectable_Job * -0.129551 + df.Good_Salary * -0.133278 + df.Convenient_Working_Hours *  -0.061196 + df.Personal_Development * 0.104857 + df.Contribution_to_Society * 0.211846 + df.Challenging_Interesting_Work * 0.189582 + df.Crime_Fighting * 0.177240
Misconduct_Index - Combine Variable
df['Misconduct_Index'] = df.Conviction_in_Court_Dico + df.Criminal_Record_Dico + df.Army_Disciplinary_Dico
United_Commander_or_Kazin - Combine Variable
df['United_Commander_or_Kazin'] = df.Commander_Army_Dico + df.Kazin_Army_Dico
United_Employment_Problems - Combine Variable
df['Financial_Difficulties_Dico_Rotated'] = df['Financial_Difficulties_Dico'] ^ 1
df['United_Employment_Problems'] = df.Financial_Difficulties_Dico_Rotated + df.Unemployment_Dico
class_counts_U_E_P = df['United_Employment_Problems'].value_counts()
###print(class_counts_U_E_P)
Small_Class_Dico_Index - Combine Variable
df['Small_Class_Dico_Index'] = df.Relevant_Education_Dico + df.Kaba_Grade_51_54_Dico + df.Past_Permanent_Officer_Dico + df.Underweight_BMI_Dumi + df.Another_Job_Nomination_Dico
Interests_and_Activities_Index - Combine Variable
df['Science_Rotated'] = df['Science'] ^ 1
df['Technology_and_Computers_Rotated'] = df['Technology_and_Computers'] ^ 1
df['Art_Rotated'] = df['Art'] ^ 1
df['Interests_and_Activities_Index'] = df.Science_Rotated + df.Technology_and_Computers_Rotated + df.Art_Rotated + df.Theater + df.Cooking + df.Volunteering
class_counts_Interests_and_Activities_Index = df['Interests_and_Activities_Index'].value_counts()
###print(class_counts_Interests_and_Activities_Index)
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
Gold List
Gibushon_Sofi_Gold_List = pd.DataFrame(df, columns=["ID_Num", "Education_and_Inteligence_Index", "Job_Motivators_Index", "United_Commander_or_Kazin", "Interests_and_Activities_Index", "Age_Num", "Hebrew_Meam_Num", "Temp_Mean_Num"])
Change Lists Variables Type
for col in Gibushon_Sofi_Gold_List:
    if col in Gibushon_Sofi_Gold_List.columns:
        Gibushon_Sofi_Gold_List[col] = Gibushon_Sofi_Gold_List[col].astype(np.float64)
Drop Missing Values
Gibushon_Sofi_Gold_List = Gibushon_Sofi_Gold_List.dropna()
---- Rama Grade ----
Educational achievement index - Combine Variable
df['Rama_Educational_achievement_index'] = df.Graduation_Average_85_Up_Dico + df.English_4_5_Units_Num_Dico + df.Math_4_5_Units_Num_Dico + df.Academic_Education_Dico + df.Psyc_Test_600_Up_Dico
United_Commander_or_Kazin - Combine Variable
df['Rama_United_Commander_or_Kazin'] = df.Commander_Army_Dico + df.Kazin_Army_Dico
Misconduct_Index - Combine Variable
df['Rama_Index_Criminal_History'] = df.Previous_Arrest_Dico + df.Criminal_Record_Dico + df.Army_Disciplinary_Dico + df.Arrest_Prison_Army_Dico + df.Conviction_Army_Dico
Sacham_officer_Dico
Married_Dico
Drinking_Alcohol_Frequ_Num
Number_of_Attempts_Num
Work_Perceived_Maching_Num
Temp_Mean_Num
# List of variables for which to calculate the average
Rama_Temp_variables = [
    'Temper_Control_2_Num',
    'Temper_Control_5_Num'
]

# Create a new column 'Temp_Mean_Num' containing the average of the specified variables
df['Rama_Temp_Mean_Num'] = df[Rama_Temp_variables].mean(axis=1)

# Display the modified data frame
#print(df)
Job_Motivators_Index - Combine Variable
df['Rama_Job_Motivators_Index'] = df.Wearing_Uniform * -0.097382 + df.Good_Salary * -0.065341 + df.Exercise_Authority * -0.080737 + df.Respectable_Job * -0.112960 + df.Challenging_Interesting_Work * 0.072071 + df.Convenient_Working_Hours * -0.072850 + df.Contribution_to_Society * 0.085553 + df.The_Action_In_Work * -0.097059 + df.Personal_Development * 0.075 + df.Interaction_With_People * 0.075
Interests_and_Activities_Index - Combine Variable
df['Rama_Interests_and_Activities_Index'] = df.Meeting_With_Friends * 0.097476 + df.Technology_and_Computers * -0.074211 + df.Theater * -0.095627 + df.Actuavlia * 0.066915 + df.Psychology * 0.051 + df.Managing_Healthy_Lifestyle * 0.051
Gold List
Rama_Sofi_Gold_List = pd.DataFrame(df, columns=["ID_Num", "Rama_Educational_achievement_index", "Rama_United_Commander_or_Kazin", "Rama_Index_Criminal_History", "Sacham_officer_Dico", "Married_Dico", "Drinking_Alcohol_Frequ_Num", "Work_Perceived_Maching_Num", "Rama_Temp_Mean_Num", "Number_of_Attempts_Num"])
Change Lists Variables Type
for col in Rama_Sofi_Gold_List:
    if col in Rama_Sofi_Gold_List.columns:
        Rama_Sofi_Gold_List[col] = Rama_Sofi_Gold_List[col].astype(np.float64)
Drop Missing Values
Rama_Sofi_Gold_List = Rama_Sofi_Gold_List.dropna()
---- Dapar Grade ----
Educational achievement index - Combine Variable
df['Dapar_Educational_achievement_index'] = df.Graduation_Average_85_Up_Dico + df.English_4_5_Units_Num_Dico + df.Math_4_5_Units_Num_Dico + df.Academic_Education_Dico + df.Psyc_Test_600_Up_Dico
Psych_Tests_Subjective_Num
class_counts_Psych_Tests_Subjective_Num = df['Psych_Tests_Subjective_Num'].value_counts()
###print(class_counts_Psych_Tests_Subjective_Num)
Kaba_Grade_51_54_Dico
Kaba_Grade_55_UP_Dico
Married_Dico
Age_Num
Special_Unit_Army_Dico
Dapar_Hebrew_Failurer_Dico
Job_Motivators_Index - Combine Variable
df['Dapar_Job_Motivators_Index'] = df.Personal_Development * 0.158877 + df.The_Action_In_Work * -0.134249 + df.Diversity_at_Work * 0.139854 + df.Assistance_to_Citizens *-0.105701 + df.Wearing_Uniform * -0.107838  + df.Crime_Fighting * 0.082 + df.Challenging_Interesting_Work * 0.098153  + df.Contribution_to_Society * 0.063  + df.Good_Salary * -0.063  + df.Convenient_Working_Hours * -0.081352 + df.Exercise_Authority * -0.054  + df.Use_Force * -0.098919
Interests_and_Activities_Index - Combine Variable
df['Dapar_Interests_and_Activities_Index'] = df.Science * 0.132 + df.Economy * 0.132 + df.Cooking * -0.1278 + df.Art * -0.105 + df.Actuavlia * 0.110 + df.Meeting_With_Friends * 0.076 + df.Psychology * 0.100 + df.Web_Surfing * 0.065 + df.Technology_and_Computers * 0.077
Gold List
Dapar_Sofi_Gold_List = pd.DataFrame(df, columns=["ID_Num","Dapar_Educational_achievement_index", "Psych_Tests_Subjective_Num", "Kaba_Grade_51_54_Dico", "Kaba_Grade_55_UP_Dico", "Married_Dico", "Special_Unit_Army_Dico", "Dapar_Job_Motivators_Index", "Dapar_Interests_and_Activities_Index", "Dapar_Hebrew_Failurer_Last_Attempt_Dico"])
Dapar_Sofi_Gold_List
         ID_Num  Dapar_Educational_achievement_index  \
0      37107588                                    4   
1     211968169                                    1   
2     340866375                                    1   
3     206253106                                    0   
4     310274717                                    0   
...         ...                                  ...   
2486  318256278                                    0   
2488   21939632                                    2   
2492   39169396                                    5   
2493   57501777                                    5   
2494   32794695                                    5   

      Psych_Tests_Subjective_Num  Kaba_Grade_51_54_Dico  \
0                              5                      0   
1                              6                      0   
2                              5                      0   
3                              4                      0   
4                              3                      0   
...                          ...                    ...   
2486                           5                      0   
2488                           5                      0   
2492                           4                      0   
2493                           6                      0   
2494                           6                      0   

      Kaba_Grade_55_UP_Dico Married_Dico  Special_Unit_Army_Dico  \
0                         1            1                     0.0   
1                         1            0                     0.0   
2                         0            1                     0.0   
3                         0            0                     0.0   
4                         0            1                     1.0   
...                     ...          ...                     ...   
2486                      0            0                     0.0   
2488                      0            1                     0.0   
2492                      0            1                     0.0   
2493                      1            0                     0.0   
2494                      1            1                     0.0   

      Dapar_Job_Motivators_Index  Dapar_Interests_and_Activities_Index  \
0                       0.459884                                0.4840   
1                       0.112678                                0.2362   
2                      -0.113797                                0.0582   
3                       0.023862                               -0.1568   
4                       0.039299                                0.0812   
...                          ...                                   ...   
2486                    0.039299                                0.0042   
2488                    0.244731                                0.1320   
2492                    0.161153                               -0.0518   
2493                    0.244731                                0.1362   
2494                    0.280379                                0.3420   

      Dapar_Hebrew_Failurer_Last_Attempt_Dico  
0                                           0  
1                                           0  
2                                           0  
3                                           0  
4                                           0  
...                                       ...  
2486                                        0  
2488                                        0  
2492                                        0  
2493                                        0  
2494                                        0  

[2249 rows x 10 columns]
Change Lists Variables Type
for col in Dapar_Sofi_Gold_List:
    if col in Dapar_Sofi_Gold_List.columns:
        Dapar_Sofi_Gold_List[col] = Dapar_Sofi_Gold_List[col].astype(np.float64)
Drop Missing Values
Dapar_Sofi_Gold_List = Dapar_Sofi_Gold_List.dropna()
---- Hebrew Grade ----
Educational achievement index - Combine Variable
df['Heb_Educational_achievement_index'] = df.Graduation_Average_85_Up_Dico + df.English_4_5_Units_Num_Dico + df.Math_4_5_Units_Num_Dico + df.Academic_Education_Dico + df.Psyc_Test_600_Up_Dico
Hebrew_Meam_Num
Cigarettes_Dico
Service_Period_Commitment_Dico
Married_Dico
Age_Num
Sacham_officer_Dico
Dapar_Hebrew_Failurer_Dico
Evaluation_Center_Filed_Dico
Max_Procedure_Duration_Num
Drinking_Alcohol_Frequ_Num
Work_Perceived_Maching_Num
Job_Motivators_Index - Combine Variable
df['Heb_Job_Motivators_Index'] = df.Personal_Development * 0.206 + df.Convenient_Working_Hours * -0.199 + df.Wearing_Uniform * -0.178 + df.Good_Salary *-0.176 + df.The_Action_In_Work * -0.170  + df.Contribution_to_Society * 0.151 + df.Use_Force * -0.150  + df.Interaction_With_People * 0.125  + df.Challenging_Interesting_Work * 0.119  + df.Diversity_at_Work * 0.114 + df.Exercise_Authority * -0.054  + df.Exercise_Authority * -0.108
Interests_and_Activities_Index - Combine Variable
df['Heb_Interests_and_Activities_Index'] = df.Actuavlia * 0.24 + df.Politics * 0.175 + df.Sport * -0.128 + df.Literature * 0.109 + df.Meeting_With_Friends * 0.095 + df.Art * -0.093 + df.Psychology * 0.068 + df.Enjoy_Parties_Bars * -0.065 + df.Extreme_Sports * -0.077 + df.Gambling * -0.081
Gold List
Heb_Sofi_Gold_List = pd.DataFrame(df, columns=["ID_Num", "Heb_Educational_achievement_index", "Hebrew_Meam_Num", "Service_Period_Commitment_Dico", "Age_Num", "Sacham_officer_Dico", "Dapar_Hebrew_Failurer_Last_Attempt_Dico", "Evaluation_Center_Filed_Last_Attempt_Dico", "Max_Procedure_Duration_Num", "Work_Perceived_Maching_Num", "Heb_Job_Motivators_Index", "Heb_Interests_and_Activities_Index"])
Change Lists Variables Type
for col in Heb_Sofi_Gold_List:
    if col in Heb_Sofi_Gold_List.columns:
        Heb_Sofi_Gold_List[col] = Heb_Sofi_Gold_List[col].astype(np.float64)
Drop Missing Values
Heb_Sofi_Gold_List = Heb_Sofi_Gold_List.dropna()
---- Normot Test Grade ----
Hebrew_Meam_Num
Work_Perceived_Maching_Num
Number_of_Attempts_Num
Volunteering_Dico
Married_Dico
Nation_Dico
Previous_Job_Salary_Num
Dapar_Grade_3_Less_Dico
Salary_Expectations_Num
Mental_Difficulties_Dico
United_Employment_Problems
Job_Motivators_Index - Combine Variable
df['Normot_Job_Motivators_Index'] = df.The_Action_In_Work * 0.158 + df.Default_Employment * 0.130 + df.Employment_Stability * -0.129 + df.Exercise_Authority *0.119 + df.Contribution_to_Society * -0.105  + df.Wearing_Uniform * 0.097 + df.Good_Salary * 0.090  + df.Personal_Development * -0.089  + df.Independence_and_Autonomy * 0.075  + df.Use_Force * 0.069
Interests_and_Activities_Index - Combine Variable
df['Normot_Interests_and_Activities_Index'] = df.Literature * -0.135 + df.Enjoy_Parties_Bars * 0.108 + df.Gambling * 0.097
Gold List
Normot_Sofi_Gold_List = pd.DataFrame(df, columns=["ID_Num", "Hebrew_Meam_Num", "Work_Perceived_Maching_Num", "Number_of_Attempts_Num", "Nation_Dico", "Previous_Job_Salary_Num", "Salary_Expectations_Num", "Mental_Difficulties_Dico", "Normot_Job_Motivators_Index", "Normot_Interests_and_Activities_Index"])
Change Lists Variables Type
for col in Normot_Sofi_Gold_List:
    if col in Normot_Sofi_Gold_List.columns:
        Normot_Sofi_Gold_List[col] = Normot_Sofi_Gold_List[col].astype(np.float64)
Drop Missing Values
Normot_Sofi_Gold_List = Normot_Sofi_Gold_List.dropna()
---- Personality Disqualification ----
Salary_Expectations_Num
United_Commander_or_Kazin
Psyc_Test_450_Less_Dico
Psyc_Test_600_Up_Dico
Psyc_Test_450_600_Dico
Math_4_5_Units_Num_Dico
Combat_Service_Army_Dico
Chronic_Disease_Dico
Relevant_Job_Experience_Dico
Work_Perceived_Maching_Num
Gender_Dico
Actuavlia
Max_Procedure_Duration_Num
Saham_Officer_Past_Dico
Nation_Dico
Job_Motivators_Index - Combine Variable
df['Personality_Dis_Job_Motivators_Index'] = df.Convenient_Working_Hours * -1.121235 + df.Assistance_to_Citizens * -0.619778 + df.Employment_Stability * 0.48454 + df.Interaction_With_People * 0.258155 + df.Wearing_Uniform * 0.52356  + df.Recommendation * 0.349112 + df.Contribution_to_Society * -0.206432  + df.The_Action_In_Work * -0.375042  + df.Crime_Fighting * -0.365593
Gold List
Personality_Diss_Sofi_Gold_List = pd.DataFrame(df, columns=["ID_Num", "Salary_Expectations_Num", "United_Commander_or_Kazin", "Psyc_Test_450_600_Dico", "Psyc_Test_450_Less_Dico", "Psyc_Test_600_Up_Dico", "Math_4_5_Units_Num_Dico", "Combat_Service_Army_Dico", "Chronic_Disease_Dico", "Relevant_Job_Experience_Dico", "Work_Perceived_Maching_Num", "Gender_Dico", "Actuavlia", "Max_Procedure_Duration_Num", "Saham_Officer_Past_Dico", "Nation_Dico"])
Change Lists Variables Type
for col in Personality_Diss_Sofi_Gold_List:
    if col in Personality_Diss_Sofi_Gold_List.columns:
        Personality_Diss_Sofi_Gold_List[col] = Personality_Diss_Sofi_Gold_List[col].astype(np.float64)
Drop Missing Values
Personality_Diss_Sofi_Gold_List = Personality_Diss_Sofi_Gold_List.dropna()
---- Gibushon Grade Gold List ----
Psyc_Test_Index
Gibushon_Job_Motivators_Index
United_Commander_or_Kazin
Age_Num
Hebrew_1_Expressive_Num
Gibushon_Job_Interests_and_Activities_Index
Job_Motivators_Index - Combine Variable
df['Gibushon_Job_Motivators_Index'] = df.Contribution_to_Society * 0.172069  + df.Independence_and_Autonomy * -0.183738  + df.Crime_Fighting * 0.182454  + df.Challenging_Interesting_Work * 0.159587  + df.Good_Salary * -0.153263  + df.Personal_Development * 0.118235  + df.Diversity_at_Work * 0.069619  + df.Employment_Stability * 0.074453  + df.Convenient_Working_Hours *  -0.042256 + df.Convenient_Work_Location * -0.056902  + df.Use_Force *  -0.057798 + df.Exercise_Authority * -0.094080  + df.Social_Benefits * -0.088683  + df.Default_Employment * -0.120173  + df.Respectable_Job *   + df.Wearing_Uniform *  -0.097522
df['Gibushon_Job_Interests_and_Activities_Index'] = df.Cooking * 0.182 + df.Extreme_Sports * 0.075 + df.Technology_and_Computers * -0.072 + df.Nature_and_Trips * -0.074 + df.Gambling * -0.085 + df.Science * -0.117
Gold List
Gibushon_Grade_Sofi_Gold_List = pd.DataFrame(df, columns=["ID_Num", "Psyc_Test_Index", "Gibushon_Job_Motivators_Index", "United_Commander_or_Kazin", "Age_Num", "Hebrew_1_Expressive_Num", "Gibushon_Job_Interests_and_Activities_Index"])
Change Lists Variables Type
for col in Gibushon_Grade_Sofi_Gold_List:
    if col in Gibushon_Grade_Sofi_Gold_List.columns:
        Gibushon_Grade_Sofi_Gold_List[col] = Gibushon_Grade_Sofi_Gold_List[col].astype(np.float64)
Drop Missing Values
Gibushon_Grade_Sofi_Gold_List = Gibushon_Grade_Sofi_Gold_List.dropna()
---- Gius Result Gold List ----
United_Commander_or_Kazin
Work_Perceived_Maching_Num
Saham_Officer_Past_Dico
Misconduct_Index
Number_of_Attempts_Num
Psychiatric_Drugs_Dico
Achievements_Preception_Num
Physical_Fitness_Frequ_Num
Weight_Num
Gius_Interests_and_Activities_Index
Gius_Job_Motivators_Index
Gius_Target
df['Gius_Interests_and_Activities_Index'] = df.Exercise_Authority * -0.812 + df.Personal_Development * 0.335 + df.Diversity_at_Work * 0.239749 + df.Contribution_to_Society * 0.181659 + df.Convenient_Work_Location * 0.320472  + df.Respectable_Job * -0.193094 + df.Good_Salary * -0.585902  + df.The_Action_In_Work * -0.377658  + df.Manage_and_Command * -0.349456
df['Gius_Job_Motivators_Index'] = df.Enjoy_Parties_Bars * -0.726507 + df.Technology_and_Computers * -0.502814 + df.Meeting_With_Friends * 0.336094 + df.Actuavlia * 0.39675 + df.Healt * 0.254358 + df.Volunteering * 0.391669 + df.Cooking * 0.21451 + df.Managing_Healthy_Lifestyle * 0.173105 + df.Psychology * -0.212941 + df.Science * -0.315026 + df.Theater * -0.312719
Gold List
Gius_Sofi_Gold_List = pd.DataFrame(df, columns=["ID_Num", "United_Commander_or_Kazin","Work_Perceived_Maching_Num","Saham_Officer_Past_Dico","Misconduct_Index","Number_of_Attempts_Num","Psychiatric_Drugs_Dico","Achievements_Preception_Num","Physical_Fitness_Frequ_Num","Weight_Num","Gius_Interests_and_Activities_Index","Gius_Job_Motivators_Index"])
Change Lists Variables Type
for col in Gius_Sofi_Gold_List:
    if col in Gius_Sofi_Gold_List.columns:
        Gius_Sofi_Gold_List[col] = Gius_Sofi_Gold_List[col].astype(np.float64)
Drop Missing Values
Gius_Sofi_Gold_List = Gius_Sofi_Gold_List.dropna()
---- Gibushon_Dico_Gold_List ----
Gold List
Final_Gibushon_Dico_Gold_List = pd.DataFrame(df, columns=["ID_Num", "Hebrew_1_Expressive_Num","United_Commander_or_Kazin","Misconduct_Index","English_3_Units_Num_Dico","Job_Motivators_Index","Interests_and_Activities_Index","Previous_Job_Salary_Num","Psychiatric_Drugs_Dico","Evaluation_Center_Filed_Last_Attempt_Dico","Year_of_Service_Army_Dico", "Number_of_Attempts_Num"])
Change Lists Variables Type
for col in Final_Gibushon_Dico_Gold_List:
    if col in Final_Gibushon_Dico_Gold_List.columns:
        Final_Gibushon_Dico_Gold_List[col] = Final_Gibushon_Dico_Gold_List[col].astype(np.float64)
Drop Missing Values
Final_Gibushon_Dico_Gold_List = Final_Gibushon_Dico_Gold_List.dropna()
Final_Gibushon_Dico_Gold_List
           ID_Num  Hebrew_1_Expressive_Num  United_Commander_or_Kazin  \
0      37107588.0                      5.0                        0.0   
1     211968169.0                      6.0                        1.0   
2     340866375.0                      6.0                        0.0   
3     206253106.0                      4.0                        0.0   
4     310274717.0                      6.0                        0.0   
...           ...                      ...                        ...   
2486  318256278.0                      5.0                        0.0   
2488   21939632.0                      2.0                        0.0   
2492   39169396.0                      5.0                        0.0   
2493   57501777.0                      6.0                        2.0   
2494   32794695.0                      7.0                        0.0   

      Misconduct_Index  English_3_Units_Num_Dico  Job_Motivators_Index  \
0                  0.0                       0.0              0.416883   
1                  0.0                       0.0              0.099965   
2                  0.0                       1.0              0.257007   
3                  0.0                       0.0              0.156437   
4                  2.0                       0.0              0.259535   
...                ...                       ...                   ...   
2486               0.0                       1.0              0.299684   
2488               2.0                       1.0             -0.293880   
2492               0.0                       0.0              0.312026   
2493               1.0                       0.0             -0.133318   
2494               0.0                       0.0              0.094945   

      Interests_and_Activities_Index  Previous_Job_Salary_Num  \
0                                1.0                      4.0   
1                                3.0                      2.0   
2                                5.0                      3.0   
3                                3.0                      3.0   
4                                3.0                      4.0   
...                              ...                      ...   
2486                             4.0                      5.0   
2488                             3.0                      2.0   
2492                             4.0                      3.0   
2493                             3.0                      3.0   
2494                             4.0                      2.0   

      Psychiatric_Drugs_Dico  Evaluation_Center_Filed_Last_Attempt_Dico  \
0                        0.0                                        0.0   
1                        0.0                                        0.0   
2                        0.0                                        1.0   
3                        0.0                                        0.0   
4                        0.0                                        0.0   
...                      ...                                        ...   
2486                     0.0                                        0.0   
2488                     1.0                                        0.0   
2492                     0.0                                        0.0   
2493                     0.0                                        0.0   
2494                     0.0                                        0.0   

      Year_of_Service_Army_Dico  Number_of_Attempts_Num  
0                           0.0                     0.0  
1                           0.0                     0.0  
2                           0.0                     1.0  
3                           0.0                     0.0  
4                           0.0                     1.0  
...                         ...                     ...  
2486                        0.0                     0.0  
2488                        0.0                     0.0  
2492                        0.0                     1.0  
2493                        0.0                     0.0  
2494                        0.0                     0.0  

[2249 rows x 12 columns]
Make predictions on the new data
Gibushon Final Grade
#Gibushon_Sofi_Gold_List
import pandas as pd
import joblib
import pandas as pd
import joblib

# Load the model from the file
Gibushon_Sofi_loaded_model = joblib.load('Gibushon_Final_Model_Linear_Regression.pkl')

# Assuming Gibushon_Sofi_Gold_List is a DataFrame with "ID_Num" as the index column
# Drop the "ID_Num" column from the input data
Gibushon_Sofi_Gold_List_without_index = Gibushon_Sofi_Gold_List.drop('ID_Num', axis=1)

# Use the loaded model to make predictions on the new data
y_Gibushon_Final_Grade = Gibushon_Sofi_loaded_model.predict(Gibushon_Sofi_Gold_List_without_index)

# Create a DataFrame with the predictions
df_gibushon_Sofi = pd.DataFrame(y_Gibushon_Final_Grade, index=Gibushon_Sofi_Gold_List.index, columns=['Predicted_Gibushon_Final_Grade'])

# Merge the "ID_Num" index variable back into the DataFrame
df_gibushon_Sofi['ID_Num'] = Gibushon_Sofi_Gold_List.ID_Num

# Save the DataFrame to a CSV file
df_gibushon_Sofi.to_csv('predicted_grades_with_id.csv', index=False)

# Print the DataFrame or use it as needed
print(df_gibushon_Sofi)
      Predicted_Gibushon_Final_Grade       ID_Num
0                           3.017762   37107588.0
1                           3.124436  211968169.0
2                           3.377852  340866375.0
3                           2.204261  206253106.0
4                           3.202141  310274717.0
...                              ...          ...
2486                        3.453804  318256278.0
2488                        1.455752   21939632.0
2492                        3.652308   39169396.0
2493                        3.563517   57501777.0
2494                        3.747548   32794695.0

[2249 rows x 2 columns]
Rama
Rama_Sofi_Gold_List
           ID_Num  Rama_Educational_achievement_index  \
0      37107588.0                                 4.0   
1     211968169.0                                 1.0   
2     340866375.0                                 1.0   
3     206253106.0                                 0.0   
4     310274717.0                                 0.0   
...           ...                                 ...   
2486  318256278.0                                 0.0   
2488   21939632.0                                 2.0   
2492   39169396.0                                 5.0   
2493   57501777.0                                 5.0   
2494   32794695.0                                 5.0   

      Rama_United_Commander_or_Kazin  Rama_Index_Criminal_History  \
0                                0.0                          0.0   
1                                1.0                          0.0   
2                                0.0                          0.0   
3                                0.0                          0.0   
4                                0.0                          3.0   
...                              ...                          ...   
2486                             0.0                          0.0   
2488                             0.0                          2.0   
2492                             0.0                          0.0   
2493                             2.0                          1.0   
2494                             0.0                          0.0   

      Sacham_officer_Dico  Married_Dico  Drinking_Alcohol_Frequ_Num  \
0                     1.0           1.0                         2.0   
1                     0.0           0.0                         1.0   
2                     0.0           1.0                         2.0   
3                     0.0           0.0                         1.0   
4                     0.0           1.0                         3.0   
...                   ...           ...                         ...   
2486                  0.0           0.0                         1.0   
2488                  0.0           1.0                         3.0   
2492                  0.0           1.0                         1.0   
2493                  0.0           0.0                         2.0   
2494                  1.0           1.0                         2.0   

      Work_Perceived_Maching_Num  Rama_Temp_Mean_Num  Number_of_Attempts_Num  
0                            6.0                 4.0                     0.0  
1                            6.0                 3.0                     0.0  
2                            5.0                 4.0                     1.0  
3                            5.0                 3.5                     0.0  
4                            6.0                 3.5                     1.0  
...                          ...                 ...                     ...  
2486                         5.0                 4.0                     0.0  
2488                         4.0                 2.5                     0.0  
2492                         5.0                 3.0                     1.0  
2493                         5.0                 3.5                     0.0  
2494                         7.0                 4.0                     0.0  

[2249 rows x 10 columns]
import pandas as pd
import joblib
import pandas as pd
import joblib

# Load the model from the file
Rama_loaded_model = joblib.load('Rama_Final_Model_Linear_Regression.pkl')

# Assuming Gibushon_Sofi_Gold_List is a DataFrame with "ID_Num" as the index column
# Drop the "ID_Num" column from the input data
Rama_Gold_List_without_index = Rama_Sofi_Gold_List.drop('ID_Num', axis=1)

# Use the loaded model to make predictions on the new data
y_Rama_Final_Grade = Rama_loaded_model.predict(Rama_Gold_List_without_index)

# Create a DataFrame with the predictions
df_Rama_final_grade = pd.DataFrame(y_Rama_Final_Grade, index=Rama_Sofi_Gold_List.index, columns=['Predicted_Rama'])

# Merge the "ID_Num" index variable back into the DataFrame
df_Rama_final_grade['ID_Num'] = Rama_Sofi_Gold_List.ID_Num

# Save the DataFrame to a CSV file
df_Rama_final_grade.to_csv('predicted_grades_with_id.csv', index=False)

# Print the DataFrame or use it as needed
print(df_Rama_final_grade)
      Predicted_Rama       ID_Num
0           4.498049   37107588.0
1           3.885744  211968169.0
2           3.923235  340866375.0
3           3.519422  206253106.0
4           3.500886  310274717.0
...              ...          ...
2486        3.549957  318256278.0
2488        3.730371   21939632.0
2492        4.222785   39169396.0
2493        4.501958   57501777.0
2494        4.661801   32794695.0

[2249 rows x 2 columns]
Dapar
Dapar_Sofi_Gold_List
           ID_Num  Dapar_Educational_achievement_index  \
0      37107588.0                                  4.0   
1     211968169.0                                  1.0   
2     340866375.0                                  1.0   
3     206253106.0                                  0.0   
4     310274717.0                                  0.0   
...           ...                                  ...   
2486  318256278.0                                  0.0   
2488   21939632.0                                  2.0   
2492   39169396.0                                  5.0   
2493   57501777.0                                  5.0   
2494   32794695.0                                  5.0   

      Psych_Tests_Subjective_Num  Kaba_Grade_51_54_Dico  \
0                            5.0                    0.0   
1                            6.0                    0.0   
2                            5.0                    0.0   
3                            4.0                    0.0   
4                            3.0                    0.0   
...                          ...                    ...   
2486                         5.0                    0.0   
2488                         5.0                    0.0   
2492                         4.0                    0.0   
2493                         6.0                    0.0   
2494                         6.0                    0.0   

      Kaba_Grade_55_UP_Dico  Married_Dico  Special_Unit_Army_Dico  \
0                       1.0           1.0                     0.0   
1                       1.0           0.0                     0.0   
2                       0.0           1.0                     0.0   
3                       0.0           0.0                     0.0   
4                       0.0           1.0                     1.0   
...                     ...           ...                     ...   
2486                    0.0           0.0                     0.0   
2488                    0.0           1.0                     0.0   
2492                    0.0           1.0                     0.0   
2493                    1.0           0.0                     0.0   
2494                    1.0           1.0                     0.0   

      Dapar_Job_Motivators_Index  Dapar_Interests_and_Activities_Index  \
0                       0.459884                                0.4840   
1                       0.112678                                0.2362   
2                      -0.113797                                0.0582   
3                       0.023862                               -0.1568   
4                       0.039299                                0.0812   
...                          ...                                   ...   
2486                    0.039299                                0.0042   
2488                    0.244731                                0.1320   
2492                    0.161153                               -0.0518   
2493                    0.244731                                0.1362   
2494                    0.280379                                0.3420   

      Dapar_Hebrew_Failurer_Last_Attempt_Dico  
0                                         0.0  
1                                         0.0  
2                                         0.0  
3                                         0.0  
4                                         0.0  
...                                       ...  
2486                                      0.0  
2488                                      0.0  
2492                                      0.0  
2493                                      0.0  
2494                                      0.0  

[2249 rows x 10 columns]
import pandas as pd
import joblib
import pandas as pd
import joblib

# Load the model from the file
Dapar_loaded_model = joblib.load('Dapar_Final_Model_Linear_Regression.pkl')

# Assuming Dapar_Sofi_Gold_List is a DataFrame with "ID_Num" as the index column
# Drop the "ID_Num" column from the input data
Dapar_Gold_List_without_index = Dapar_Sofi_Gold_List.drop('ID_Num', axis=1)

# Use the loaded model to make predictions on the new data
y_Dapar_Final_Grade = Dapar_loaded_model.predict(Dapar_Gold_List_without_index)

# Create a DataFrame with the predictions
df_Dapar_final_grade = pd.DataFrame(y_Dapar_Final_Grade, index=Dapar_Sofi_Gold_List.index, columns=['Predicted_Dapar'])

# Merge the "ID_Num" index variable back into the DataFrame
df_Dapar_final_grade['ID_Num'] = Dapar_Sofi_Gold_List.ID_Num

# Save the DataFrame to a CSV file
df_Dapar_final_grade.to_csv('predicted_grades_with_id.csv', index=False)

# Print the DataFrame or use it as needed
print(df_Dapar_final_grade)
      Predicted_Dapar       ID_Num
0            8.440772   37107588.0
1            5.669301  211968169.0
2            4.599727  340866375.0
3            3.664198  206253106.0
4            4.812698  310274717.0
...               ...          ...
2486         4.041847  318256278.0
2488         6.080236   21939632.0
2492         6.655761   39169396.0
2493         7.505658   57501777.0
2494         8.358370   32794695.0

[2249 rows x 2 columns]
Hebrew
Heb_Sofi_Gold_List
           ID_Num  Heb_Educational_achievement_index  Hebrew_Meam_Num  \
0      37107588.0                                4.0              5.6   
1     211968169.0                                1.0              6.0   
2     340866375.0                                1.0              6.0   
3     206253106.0                                0.0              4.4   
4     310274717.0                                0.0              5.8   
...           ...                                ...              ...   
2486  318256278.0                                0.0              6.6   
2488   21939632.0                                2.0              2.8   
2492   39169396.0                                5.0              5.4   
2493   57501777.0                                5.0              6.0   
2494   32794695.0                                5.0              6.8   

      Service_Period_Commitment_Dico  Age_Num  Sacham_officer_Dico  \
0                                1.0     37.0                  1.0   
1                                1.0     23.0                  0.0   
2                                1.0     26.0                  0.0   
3                                1.0     28.0                  0.0   
4                                1.0     31.0                  0.0   
...                              ...      ...                  ...   
2486                             1.0     25.0                  0.0   
2488                             1.0     32.0                  0.0   
2492                             1.0     40.0                  0.0   
2493                             1.0     33.0                  0.0   
2494                             1.0     44.0                  1.0   

      Dapar_Hebrew_Failurer_Last_Attempt_Dico  \
0                                         0.0   
1                                         0.0   
2                                         0.0   
3                                         0.0   
4                                         0.0   
...                                       ...   
2486                                      0.0   
2488                                      0.0   
2492                                      0.0   
2493                                      0.0   
2494                                      0.0   

      Evaluation_Center_Filed_Last_Attempt_Dico  Max_Procedure_Duration_Num  \
0                                           0.0                         3.0   
1                                           0.0                         1.0   
2                                           1.0                         3.0   
3                                           0.0                         1.0   
4                                           0.0                         3.0   
...                                         ...                         ...   
2486                                        0.0                         1.0   
2488                                        0.0                         6.0   
2492                                        0.0                         1.0   
2493                                        0.0                         1.0   
2494                                        0.0                         2.0   

      Work_Perceived_Maching_Num  Heb_Job_Motivators_Index  \
0                            6.0                     0.590   
1                            6.0                     0.075   
2                            5.0                    -0.088   
3                            5.0                     0.005   
4                            6.0                     0.151   
...                          ...                       ...   
2486                         5.0                     0.151   
2488                         4.0                     0.283   
2492                         5.0                     0.270   
2493                         5.0                     0.283   
2494                         7.0                     0.397   

      Heb_Interests_and_Activities_Index  
0                                  0.308  
1                                 -0.060  
2                                  0.444  
3                                 -0.126  
4                                 -0.205  
...                                  ...  
2486                               0.156  
2488                              -0.019  
2492                               0.204  
2493                               0.047  
2494                               0.180  

[2249 rows x 12 columns]
import pandas as pd
import joblib
import pandas as pd
import joblib

# Load the model from the file
Hebrew_loaded_model = joblib.load('Hebrew_Final_Model_Linear_Regression.pkl')

# Assuming Heb_Sofi_Gold_List is a DataFrame with "ID_Num" as the index column
# Drop the "ID_Num" column from the input data
Hebrew_Gold_List_without_index = Heb_Sofi_Gold_List.drop('ID_Num', axis=1)

# Use the loaded model to make predictions on the new data
y_Hebrew_Final_Grade = Hebrew_loaded_model.predict(Hebrew_Gold_List_without_index)

# Create a DataFrame with the predictions
df_Hebrew_final_grade = pd.DataFrame(y_Hebrew_Final_Grade, index=Heb_Sofi_Gold_List.index, columns=['Predicted_Hebrew'])

# Merge the "ID_Num" index variable back into the DataFrame
df_Hebrew_final_grade['ID_Num'] = Heb_Sofi_Gold_List.ID_Num

# Save the DataFrame to a CSV file
df_Hebrew_final_grade.to_csv('predicted_grades_with_id.csv', index=False)

# Print the DataFrame or use it as needed
print(df_Hebrew_final_grade)
      Predicted_Hebrew       ID_Num
0             8.211801   37107588.0
1             7.221064  211968169.0
2             6.484300  340866375.0
3             6.730235  206253106.0
4             7.126990  310274717.0
...                ...          ...
2486          7.405397  318256278.0
2488          7.184134   21939632.0
2492          8.282882   39169396.0
2493          8.167654   57501777.0
2494          8.410011   32794695.0

[2249 rows x 2 columns]
Normot
Normot_Sofi_Gold_List
           ID_Num  Hebrew_Meam_Num  Work_Perceived_Maching_Num  \
0      37107588.0              5.6                         6.0   
1     211968169.0              6.0                         6.0   
2     340866375.0              6.0                         5.0   
3     206253106.0              4.4                         5.0   
4     310274717.0              5.8                         6.0   
...           ...              ...                         ...   
2486  318256278.0              6.6                         5.0   
2488   21939632.0              2.8                         4.0   
2492   39169396.0              5.4                         5.0   
2493   57501777.0              6.0                         5.0   
2494   32794695.0              6.8                         7.0   

      Number_of_Attempts_Num  Nation_Dico  Previous_Job_Salary_Num  \
0                        0.0          1.0                      4.0   
1                        0.0          1.0                      2.0   
2                        1.0          1.0                      3.0   
3                        0.0          1.0                      3.0   
4                        1.0          1.0                      4.0   
...                      ...          ...                      ...   
2486                     0.0          0.0                      5.0   
2488                     0.0          0.0                      2.0   
2492                     1.0          1.0                      3.0   
2493                     0.0          1.0                      3.0   
2494                     0.0          1.0                      2.0   

      Salary_Expectations_Num  Mental_Difficulties_Dico  \
0                         7.0                       0.0   
1                         3.0                       0.0   
2                         3.0                       0.0   
3                         4.0                       0.0   
4                         4.0                       0.0   
...                       ...                       ...   
2486                      3.0                       0.0   
2488                      2.0                       1.0   
2492                      4.0                       0.0   
2493                      5.0                       0.0   
2494                      7.0                       0.0   

      Normot_Job_Motivators_Index  Normot_Interests_and_Activities_Index  
0                          -0.323                                  0.000  
1                          -0.128                                  0.000  
2                           0.277                                 -0.135  
3                           0.009                                  0.000  
4                          -0.234                                  0.000  
...                           ...                                    ...  
2486                       -0.105                                 -0.135  
2488                        0.235                                 -0.135  
2492                       -0.234                                 -0.135  
2493                        0.031                                  0.000  
2494                       -0.119                                  0.000  

[2249 rows x 10 columns]
import pandas as pd
import joblib
import pandas as pd
import joblib

# Load the model from the file
Normot_loaded_model = joblib.load('Normot_Final_Model_Linear_Regression.pkl')

# Assuming Normot_Sofi_Gold_List is a DataFrame with "ID_Num" as the index column
# Drop the "ID_Num" column from the input data
Normot_Gold_List_without_index = Normot_Sofi_Gold_List.drop('ID_Num', axis=1)

# Use the loaded model to make predictions on the new data
y_Normot_Final_Grade = Normot_loaded_model.predict(Normot_Gold_List_without_index)

# Create a DataFrame with the predictions
df_Normot_final_grade = pd.DataFrame(y_Normot_Final_Grade, index=Normot_Sofi_Gold_List.index, columns=['Predicted_Normot'])

# Merge the "ID_Num" index variable back into the DataFrame
df_Normot_final_grade['ID_Num'] = Normot_Sofi_Gold_List.ID_Num

# Save the DataFrame to a CSV file
df_Normot_final_grade.to_csv('predicted_grades_with_id.csv', index=False)

# Print the DataFrame or use it as needed
print(df_Normot_final_grade)
      Predicted_Normot       ID_Num
0             0.658843   37107588.0
1             0.589567  211968169.0
2             1.925971  340866375.0
3             2.104191  206253106.0
4             0.866551  310274717.0
...                ...          ...
2486          2.402527  318256278.0
2488          5.656580   21939632.0
2492          0.686932   39169396.0
2493          1.304140   57501777.0
2494          0.031614   32794695.0

[2249 rows x 2 columns]
Personality Diss
Personality_Diss_Sofi_Gold_List
           ID_Num  Salary_Expectations_Num  United_Commander_or_Kazin  \
0      37107588.0                      7.0                        0.0   
1     211968169.0                      3.0                        1.0   
2     340866375.0                      3.0                        0.0   
3     206253106.0                      4.0                        0.0   
4     310274717.0                      4.0                        0.0   
...           ...                      ...                        ...   
2486  318256278.0                      3.0                        0.0   
2488   21939632.0                      2.0                        0.0   
2492   39169396.0                      4.0                        0.0   
2493   57501777.0                      5.0                        2.0   
2494   32794695.0                      7.0                        0.0   

      Psyc_Test_450_600_Dico  Psyc_Test_450_Less_Dico  Psyc_Test_600_Up_Dico  \
0                        0.0                      0.0                    0.0   
1                        0.0                      0.0                    1.0   
2                        0.0                      0.0                    0.0   
3                        0.0                      0.0                    0.0   
4                        0.0                      1.0                    0.0   
...                      ...                      ...                    ...   
2486                     0.0                      0.0                    0.0   
2488                     0.0                      1.0                    0.0   
2492                     0.0                      0.0                    1.0   
2493                     0.0                      0.0                    1.0   
2494                     0.0                      0.0                    1.0   

      Math_4_5_Units_Num_Dico  Combat_Service_Army_Dico  Chronic_Disease_Dico  \
0                         1.0                       0.0                   0.0   
1                         0.0                       1.0                   0.0   
2                         1.0                       1.0                   0.0   
3                         0.0                       0.0                   0.0   
4                         0.0                       0.0                   0.0   
...                       ...                       ...                   ...   
2486                      0.0                       0.0                   0.0   
2488                      1.0                       0.0                   1.0   
2492                      1.0                       0.0                   0.0   
2493                      1.0                       1.0                   0.0   
2494                      1.0                       0.0                   0.0   

      Relevant_Job_Experience_Dico  Work_Perceived_Maching_Num  Gender_Dico  \
0                              1.0                         6.0          1.0   
1                              1.0                         6.0          1.0   
2                              0.0                         5.0          1.0   
3                              1.0                         5.0          1.0   
4                              0.0                         6.0          1.0   
...                            ...                         ...          ...   
2486                           0.0                         5.0          1.0   
2488                           1.0                         4.0          1.0   
2492                           1.0                         5.0          0.0   
2493                           0.0                         5.0          1.0   
2494                           1.0                         7.0          1.0   

      Actuavlia  Max_Procedure_Duration_Num  Saham_Officer_Past_Dico  \
0           1.0                         3.0                      1.0   
1           0.0                         1.0                      0.0   
2           1.0                         3.0                      0.0   
3           0.0                         1.0                      0.0   
4           0.0                         3.0                      0.0   
...         ...                         ...                      ...   
2486        0.0                         1.0                      0.0   
2488        0.0                         6.0                      0.0   
2492        0.0                         1.0                      0.0   
2493        0.0                         1.0                      0.0   
2494        1.0                         2.0                      1.0   

      Nation_Dico  
0             1.0  
1             1.0  
2             1.0  
3             1.0  
4             1.0  
...           ...  
2486          0.0  
2488          0.0  
2492          1.0  
2493          1.0  
2494          1.0  

[2249 rows x 16 columns]
import pandas as pd
import joblib
import pandas as pd
import joblib

# Load the model and cutoff point from the file
(Personality_loaded_model, _) = joblib.load('Personality_Diss_Final_Model_L_R.pkl')

# Assuming Personality_Diss_Sofi_Gold_List is a DataFrame with "ID_Num" as the index column
# Drop the "ID_Num" column from the input data
Personality_Gold_List_without_index = Personality_Diss_Sofi_Gold_List.drop('ID_Num', axis=1)

# Use the loaded model to make predictions on the new data
Personality_Diss_Gold_Model_Predictions = Personality_loaded_model.predict_proba(Personality_Gold_List_without_index)[:, 1]

# Create a DataFrame with the predictions
df_Personality_final_grade = pd.DataFrame(Personality_Diss_Gold_Model_Predictions, index=Personality_Diss_Sofi_Gold_List.index, columns=['Predicted_Personality_Diss'])

# Merge the "ID_Num" index variable back into the DataFrame
df_Personality_final_grade['ID_Num'] = Personality_Diss_Sofi_Gold_List.ID_Num

# Save the DataFrame to a CSV file
df_Personality_final_grade.to_csv('predicted_grades_with_id.csv', index=False)

# Print the DataFrame or use it as needed
print(df_Personality_final_grade)
      Predicted_Personality_Diss       ID_Num
0                       0.376663   37107588.0
1                       0.046240  211968169.0
2                       0.645981  340866375.0
3                       0.116901  206253106.0
4                       0.084223  310274717.0
...                          ...          ...
2486                    0.077222  318256278.0
2488                    0.602197   21939632.0
2492                    0.073946   39169396.0
2493                    0.041709   57501777.0
2494                    0.080315   32794695.0

[2249 rows x 2 columns]
df_Personality_final_grade
      Predicted_Personality_Diss       ID_Num
0                       0.376663   37107588.0
1                       0.046240  211968169.0
2                       0.645981  340866375.0
3                       0.116901  206253106.0
4                       0.084223  310274717.0
...                          ...          ...
2486                    0.077222  318256278.0
2488                    0.602197   21939632.0
2492                    0.073946   39169396.0
2493                    0.041709   57501777.0
2494                    0.080315   32794695.0

[2249 rows x 2 columns]
Gibushon Grade
Gibushon_Grade_Sofi_Gold_List
           ID_Num  Psyc_Test_Index  Gibushon_Job_Motivators_Index  \
0      37107588.0              1.0                       0.505280   
1     211968169.0              3.0                       0.156756   
2     340866375.0              1.0                       0.247961   
3     206253106.0              1.0                       0.205794   
4     310274717.0              0.0                       0.428976   
...           ...              ...                            ...   
2486  318256278.0              1.0                       0.208938   
2488   21939632.0              0.0                      -0.210137   
2492   39169396.0              3.0                       0.260524   
2493   57501777.0              3.0                       0.048054   
2494   32794695.0              3.0                       0.133929   

      United_Commander_or_Kazin  Age_Num  Hebrew_1_Expressive_Num  \
0                           0.0     37.0                      5.0   
1                           1.0     23.0                      6.0   
2                           0.0     26.0                      6.0   
3                           0.0     28.0                      4.0   
4                           0.0     31.0                      6.0   
...                         ...      ...                      ...   
2486                        0.0     25.0                      5.0   
2488                        0.0     32.0                      2.0   
2492                        0.0     40.0                      5.0   
2493                        2.0     33.0                      6.0   
2494                        0.0     44.0                      7.0   

      Gibushon_Job_Interests_and_Activities_Index  
0                                          -0.189  
1                                           0.065  
2                                           0.182  
3                                           0.108  
4                                           0.185  
...                                           ...  
2486                                        0.182  
2488                                       -0.191  
2492                                        0.108  
2493                                       -0.009  
2494                                       -0.117  

[2249 rows x 7 columns]
import pandas as pd
import joblib
import pandas as pd
import joblib

# Load the model and cutoff point from the file
(Gibushon_loaded_model) = joblib.load('Gibushon_Grade_Model_Linear_Regression.pkl')

# Drop the "ID_Num" column from the input data
Gibushon_Gold_List_without_index = Gibushon_Grade_Sofi_Gold_List.drop('ID_Num', axis=1)

# Assuming Gibushon_Grade_Sofi_Gold_List is a DataFrame with "ID_Num" as the index column

# Use the loaded model to make predictions on the new data
y_Gibushon_Final_Grade = Gibushon_loaded_model.predict(Gibushon_Gold_List_without_index)

# Create a DataFrame with the predictions
df_Gibushon_grade = pd.DataFrame(y_Gibushon_Final_Grade, index=Gibushon_Grade_Sofi_Gold_List.index, columns=['Predicted_Gibushon_Grade'])

# Merge the "ID_Num" index variable back into the DataFrame
df_Gibushon_grade['ID_Num'] = Gibushon_Grade_Sofi_Gold_List.ID_Num

# Save the DataFrame to a CSV file
df_Gibushon_grade.to_csv('predicted_grades_with_id.csv', index=False)

# Print the DataFrame or use it as needed
print(df_Gibushon_grade)
      Predicted_Gibushon_Grade       ID_Num
0                     3.032249   37107588.0
1                     3.489384  211968169.0
2                     3.044592  340866375.0
3                     2.794325  206253106.0
4                     3.250757  310274717.0
...                        ...          ...
2486                  2.884404  318256278.0
2488                  1.826283   21939632.0
2492                  3.660230   39169396.0
2493                  4.192437   57501777.0
2494                  3.545976   32794695.0

[2249 rows x 2 columns]
Gius Result
Gius_Sofi_Gold_List
           ID_Num  United_Commander_or_Kazin  Work_Perceived_Maching_Num  \
0      37107588.0                        0.0                         6.0   
1     211968169.0                        1.0                         6.0   
2     340866375.0                        0.0                         5.0   
3     206253106.0                        0.0                         5.0   
4     310274717.0                        0.0                         6.0   
...           ...                        ...                         ...   
2486  318256278.0                        0.0                         5.0   
2488   21939632.0                        0.0                         4.0   
2492   39169396.0                        0.0                         5.0   
2493   57501777.0                        2.0                         5.0   
2494   32794695.0                        0.0                         7.0   

      Saham_Officer_Past_Dico  Misconduct_Index  Number_of_Attempts_Num  \
0                         1.0               0.0                     0.0   
1                         0.0               0.0                     0.0   
2                         0.0               0.0                     1.0   
3                         0.0               0.0                     0.0   
4                         0.0               2.0                     1.0   
...                       ...               ...                     ...   
2486                      0.0               0.0                     0.0   
2488                      0.0               2.0                     0.0   
2492                      0.0               0.0                     1.0   
2493                      0.0               1.0                     0.0   
2494                      1.0               0.0                     0.0   

      Psychiatric_Drugs_Dico  Achievements_Preception_Num  \
0                        0.0                          5.0   
1                        0.0                          6.0   
2                        0.0                          3.0   
3                        0.0                          5.0   
4                        0.0                          3.0   
...                      ...                          ...   
2486                     0.0                          5.0   
2488                     1.0                          2.0   
2492                     0.0                          4.0   
2493                     0.0                          6.0   
2494                     0.0                          7.0   

      Physical_Fitness_Frequ_Num  Weight_Num  \
0                            4.0        71.0   
1                            4.0        75.0   
2                            3.0       105.0   
3                            3.0        96.0   
4                            3.0        87.0   
...                          ...         ...   
2486                         4.0        88.0   
2488                         3.0        89.0   
2492                         2.0        57.0   
2493                         4.0        75.0   
2494                         4.0        90.0   

      Gius_Interests_and_Activities_Index  Gius_Job_Motivators_Index  
0                                0.756408                  -0.460926  
1                               -0.250902                  -0.313457  
2                               -1.189658                   0.634635  
3                               -0.042658                   0.804962  
4                               -0.360891                  -0.288304  
...                                   ...                        ...  
2486                             0.152675                   0.214510  
2488                            -0.237251                  -0.627745  
2492                             0.502131                   0.723709  
2493                            -0.237251                  -0.100516  
2494                             0.756408                  -0.052267  

[2249 rows x 12 columns]
import pandas as pd
import joblib
import pandas as pd
import joblib

# Load the model and cutoff point from the file
(Gius_loaded_model, _) = joblib.load('Gius_Final_Model_L_R.pkl')

# Assuming Gius_Sofi_Gold_List is a DataFrame with "ID_Num" as the index column
# Drop the "ID_Num" column from the input data
Gius_Gold_List_without_index = Gius_Sofi_Gold_List.drop('ID_Num', axis=1)

# Use the loaded model to make predictions on the new data
Gius_Gold_Model_Predictions = Gius_loaded_model.predict_proba(Gius_Gold_List_without_index)[:, 1]

# Create a DataFrame with the predictions
df_Gius_Results = pd.DataFrame(Gius_Gold_Model_Predictions, index=Gius_Sofi_Gold_List.index, columns=['Predicted_Gius_Result'])

# Merge the "ID_Num" index variable back into the DataFrame
df_Gius_Results['ID_Num'] = Gius_Sofi_Gold_List.ID_Num

# Save the DataFrame to a CSV file
df_Gius_Results.to_csv('predicted_grades_with_id.csv', index=False)

# Print the DataFrame or use it as needed
print(df_Gius_Results)
      Predicted_Gius_Result       ID_Num
0                  0.712949   37107588.0
1                  0.422558  211968169.0
2                  0.080023  340866375.0
3                  0.332841  206253106.0
4                  0.025533  310274717.0
...                     ...          ...
2486               0.365384  318256278.0
2488               0.010061   21939632.0
2492               0.528705   39169396.0
2493               0.310964   57501777.0
2494               0.737548   32794695.0

[2249 rows x 2 columns]
Final Gibushon Dico
import pandas as pd
import joblib
import pandas as pd
import joblib

# Load the model and cutoff point from the file
(Evaluation_Center_Dico_loaded_model, _) = joblib.load('Model_Logistic_Regression.pkl')

# Assuming Final_Gibushon_Dico_Gold_List  is a DataFrame with "ID_Num" as the index column
# Drop the "ID_Num" column from the input data
Evaluation_Center_Dico_Gold_List_without_index = Final_Gibushon_Dico_Gold_List .drop('ID_Num', axis=1)

# Use the loaded model to make predictions on the new data
Evaluation_Center_Dico_Gold_Model_Predictions = Evaluation_Center_Dico_loaded_model.predict_proba(Evaluation_Center_Dico_Gold_List_without_index)[:, 1]

# Create a DataFrame with the predictions
df_Evaluation_Center_Dico_Results = pd.DataFrame(Evaluation_Center_Dico_Gold_Model_Predictions, index=Final_Gibushon_Dico_Gold_List.index, columns=['Predicted_Evaluation_Center_Dico'])

# Merge the "ID_Num" index variable back into the DataFrame
df_Evaluation_Center_Dico_Results['ID_Num'] = Final_Gibushon_Dico_Gold_List .ID_Num

# Save the DataFrame to a CSV file
df_Evaluation_Center_Dico_Results.to_csv('predicted_grades_with_id.csv', index=False)

# Print the DataFrame or use it as needed
print(df_Evaluation_Center_Dico_Results)
      Predicted_Evaluation_Center_Dico       ID_Num
0                             0.552567   37107588.0
1                             0.717931  211968169.0
2                             0.601707  340866375.0
3                             0.483772  206253106.0
4                             0.272067  310274717.0
...                                ...          ...
2486                          0.752618  318256278.0
2488                          0.016364   21939632.0
2492                          0.693357   39169396.0
2493                          0.710010   57501777.0
2494                          0.694682   32794695.0

[2249 rows x 2 columns]
First Join
dataframe with all real target variables
Target_Variables_Real = pd.read_excel("C:/Users/Knowl/Desktop/‏‏SADAC System Project/1Input/3Target Variables/Targets Variables - All.XLSX")
Target_Variables_Real.head()
      ID_Num  RAMA_Target  Evaluation_Center_Target  Hebrew_Target  \
0   37107588          NaN                       NaN            NaN   
1  211968169          5.0                       NaN            NaN   
2  340866375          3.5                       2.5            NaN   
3  206253106          3.0                       4.5            NaN   
4  310274717          3.0                       2.5            NaN   

   Dapar_Target  Normot_Target  Personality_Dis_Target  \
0           NaN            NaN                     NaN   
1           NaN            1.0                     0.0   
2           NaN            2.0                     0.0   
3           NaN            6.0                     1.0   
4           NaN            1.0                     0.0   

   Personality_Dis_Safek_Target  Gibushon_Target  Gius_Target  \
0                           NaN              NaN          NaN   
1                           0.0              NaN          1.0   
2                           0.0              2.5          0.0   
3                           1.0              NaN          0.0   
4                           0.0              2.5          0.0   

   Evaluation_Center_Dico_Target  Yeodi_Liba  
0                            NaN           0  
1                            NaN           1  
2                            0.0           1  
3                            1.0           1  
4                            0.0           1  
Target_Variables_Real['Normot_Target'] = Target_Variables_Real.Normot_Target - 1
Dataframe with all real target variables & models predictions
import pandas as pd

merged_df = pd.merge(df_gibushon_Sofi, df_Rama_final_grade, on='ID_Num', how='outer')
merged_df = pd.merge(merged_df, df_Dapar_final_grade, on='ID_Num', how='outer')
merged_df = pd.merge(merged_df, df_Hebrew_final_grade, on='ID_Num', how='outer')
merged_df = pd.merge(merged_df, df_Normot_final_grade, on='ID_Num', how='outer')
merged_df = pd.merge(merged_df, df_Personality_final_grade, on='ID_Num', how='outer')
merged_df = pd.merge(merged_df, df_Gibushon_grade, on='ID_Num', how='outer')
merged_df = pd.merge(merged_df, df_Gius_Results, on='ID_Num', how='outer')
merged_df = pd.merge(merged_df, df_Evaluation_Center_Dico_Results, on='ID_Num', how='outer')
merged_df = pd.merge(merged_df, Target_Variables_Real, on='ID_Num', how='outer')



# Display the merged data frame
#merged_df
merged_df
      Predicted_Gibushon_Final_Grade       ID_Num  Predicted_Rama  \
0                           3.017762   37107588.0        4.498049   
1                           3.124436  211968169.0        3.885744   
2                           3.377852  340866375.0        3.923235   
3                           2.204261  206253106.0        3.519422   
4                           3.202141  310274717.0        3.500886   
...                              ...          ...             ...   
2244                        3.453804  318256278.0        3.549957   
2245                        1.455752   21939632.0        3.730371   
2246                        3.652308   39169396.0        4.222785   
2247                        3.563517   57501777.0        4.501958   
2248                        3.747548   32794695.0        4.661801   

      Predicted_Dapar  Predicted_Hebrew  Predicted_Normot  \
0            8.440772          8.211801          0.658843   
1            5.669301          7.221064          0.589567   
2            4.599727          6.484300          1.925971   
3            3.664198          6.730235          2.104191   
4            4.812698          7.126990          0.866551   
...               ...               ...               ...   
2244         4.041847          7.405397          2.402527   
2245         6.080236          7.184134          5.656580   
2246         6.655761          8.282882          0.686932   
2247         7.505658          8.167654          1.304140   
2248         8.358370          8.410011          0.031614   

      Predicted_Personality_Diss  Predicted_Gibushon_Grade  \
0                       0.376663                  3.032249   
1                       0.046240                  3.489384   
2                       0.645981                  3.044592   
3                       0.116901                  2.794325   
4                       0.084223                  3.250757   
...                          ...                       ...   
2244                    0.077222                  2.884404   
2245                    0.602197                  1.826283   
2246                    0.073946                  3.660230   
2247                    0.041709                  4.192437   
2248                    0.080315                  3.545976   

      Predicted_Gius_Result  Predicted_Evaluation_Center_Dico  ...  \
0                  0.712949                          0.552567  ...   
1                  0.422558                          0.717931  ...   
2                  0.080023                          0.601707  ...   
3                  0.332841                          0.483772  ...   
4                  0.025533                          0.272067  ...   
...                     ...                               ...  ...   
2244               0.365384                          0.752618  ...   
2245               0.010061                          0.016364  ...   
2246               0.528705                          0.693357  ...   
2247               0.310964                          0.710010  ...   
2248               0.737548                          0.694682  ...   

      Evaluation_Center_Target  Hebrew_Target  Dapar_Target  Normot_Target  \
0                          NaN            NaN           NaN            NaN   
1                          NaN            NaN           NaN            0.0   
2                          2.5            NaN           NaN            1.0   
3                          4.5            NaN           NaN            5.0   
4                          2.5            NaN           NaN            0.0   
...                        ...            ...           ...            ...   
2244                       NaN            NaN           NaN            NaN   
2245                       NaN            NaN           NaN            NaN   
2246                       NaN            NaN           NaN            NaN   
2247                       NaN            NaN           NaN            NaN   
2248                       NaN            NaN           NaN            NaN   

      Personality_Dis_Target  Personality_Dis_Safek_Target  Gibushon_Target  \
0                        NaN                           NaN              NaN   
1                        0.0                           0.0              NaN   
2                        0.0                           0.0              2.5   
3                        1.0                           1.0              NaN   
4                        0.0                           0.0              2.5   
...                      ...                           ...              ...   
2244                     NaN                           NaN              NaN   
2245                     NaN                           NaN              NaN   
2246                     NaN                           NaN              NaN   
2247                     NaN                           NaN              NaN   
2248                     NaN                           NaN              NaN   

      Gius_Target  Evaluation_Center_Dico_Target  Yeodi_Liba  
0             NaN                            NaN           0  
1             1.0                            NaN           1  
2             0.0                            0.0           1  
3             0.0                            1.0           1  
4             0.0                            0.0           1  
...           ...                            ...         ...  
2244          NaN                            NaN           0  
2245          NaN                            NaN           0  
2246          NaN                            NaN           0  
2247          NaN                            NaN           0  
2248          NaN                            NaN           0  

[2249 rows x 21 columns]
---- Gibushon_Dico_Gold_List ----
Gold List
Final_Gibushon_Dico_Gold_List = pd.DataFrame(merged_df, columns=["ID_Num", "Predicted_Gibushon_Final_Grade","Predicted_Rama","Predicted_Dapar","Predicted_Hebrew","Predicted_Gibushon_Grade", "Evaluation_Center_Dico_Target"])
Change Lists Variables Type
for col in Final_Gibushon_Dico_Gold_List:
    if col in Final_Gibushon_Dico_Gold_List.columns:
        Final_Gibushon_Dico_Gold_List[col] = Final_Gibushon_Dico_Gold_List[col].astype(np.float64)
Drop Missing Values
Final_Gibushon_Dico_Gold_List = Final_Gibushon_Dico_Gold_List.dropna()
Final_Gibushon_Dico_Gold_List
           ID_Num  Predicted_Gibushon_Final_Grade  Predicted_Rama  \
2     340866375.0                        3.377852        3.923235   
3     206253106.0                        2.204261        3.519422   
4     310274717.0                        3.202141        3.500886   
19    208658179.0                        2.847203        4.117379   
21    322283128.0                        2.684544        3.803976   
...           ...                             ...             ...   
2112  211612924.0                        3.139516        4.133057   
2132  322659806.0                        2.937222        3.830343   
2186  213562432.0                        3.378558        4.293581   
2224  211301981.0                        2.440957        3.458399   
2225  316525831.0                        1.569345        3.551848   

      Predicted_Dapar  Predicted_Hebrew  Predicted_Gibushon_Grade  \
2            4.599727          6.484300                  3.044592   
3            3.664198          6.730235                  2.794325   
4            4.812698          7.126990                  3.250757   
19           6.761382          7.844248                  2.431049   
21           3.599754          7.016970                  2.552013   
...               ...               ...                       ...   
2112         4.472370          7.291395                  3.412866   
2132         4.540061          7.322234                  2.272798   
2186         4.692237          7.478305                  3.464836   
2224         2.969674          6.395564                  2.738124   
2225         4.510130          6.745985                  2.115783   

      Evaluation_Center_Dico_Target  
2                               0.0  
3                               1.0  
4                               0.0  
19                              0.0  
21                              1.0  
...                             ...  
2112                            1.0  
2132                            1.0  
2186                            1.0  
2224                            0.0  
2225                            0.0  

[193 rows x 7 columns]
Models Impowerment - Models Predictions as Features
Evaluation_Center_Target - Prediction Improvment
Evaluation_Center_Target = pd.DataFrame(merged_df, columns=["ID_Num", 'Predicted_Gibushon_Final_Grade', 'Predicted_Rama', "Predicted_Dapar", "Predicted_Hebrew", "Predicted_Normot", "Predicted_Personality_Diss", "Predicted_Gibushon_Grade", "Predicted_Gius_Result", 'Evaluation_Center_Target'])
Evaluation_Center_Target = Evaluation_Center_Target.dropna()
import pandas as pd
import statsmodels.api as sm
from sklearn import linear_model

# Define predictors and response variable
x = Evaluation_Center_Target[Evaluation_Center_Target.columns[Evaluation_Center_Target.columns.isin(['Predicted_Gibushon_Final_Grade',"Predicted_Gibushon_Grade"])]]
y = Evaluation_Center_Target['Evaluation_Center_Target']

# Add constant to the predictors
x = sm.add_constant(x)

# Create a linear regression model
regr = linear_model.LinearRegression()
regr.fit(x, y)

# Fit OLS regression model
model = sm.OLS(y, x).fit()

# Make predictions
Evaluation_Center_Target['Evaluation_Center_Target'] = model.predict(x)

# Print model summary and description
print_model = model.summary()
print("Model Summary:")
print(print_model)

# Print model description
print("\nModel Description:")
print("The model describes the relationship between the predicted Gibushon final grade and Gibushon grade, taking into account the constant term.")
Model Summary:
                               OLS Regression Results                               
====================================================================================
Dep. Variable:     Evaluation_Center_Target   R-squared:                       0.297
Model:                                  OLS   Adj. R-squared:                  0.289
Method:                       Least Squares   F-statistic:                     40.08
Date:                      Tue, 09 Apr 2024   Prob (F-statistic):           3.00e-15
Time:                              16:13:25   Log-Likelihood:                -239.36
No. Observations:                       193   AIC:                             484.7
Df Residuals:                           190   BIC:                             494.5
Df Model:                                 2                                         
Covariance Type:                  nonrobust                                         
==================================================================================================
                                     coef    std err          t      P>|t|      [0.025      0.975]
--------------------------------------------------------------------------------------------------
const                             -0.0146      0.378     -0.039      0.969      -0.761       0.732
Predicted_Gibushon_Final_Grade     0.5476      0.180      3.048      0.003       0.193       0.902
Predicted_Gibushon_Grade           0.4846      0.228      2.126      0.035       0.035       0.934
==============================================================================
Omnibus:                        4.372   Durbin-Watson:                   2.254
Prob(Omnibus):                  0.112   Jarque-Bera (JB):                4.354
Skew:                           0.366   Prob(JB):                        0.113
Kurtosis:                       2.928   Cond. No.                         29.7
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

Model Description:
The model describes the relationship between the predicted Gibushon final grade and Gibushon grade, taking into account the constant term.
from joblib import dump

# Save the model using joblib.dump
joblib.dump(model, 'Gibushon_Final_Model_Improved.pkl')
['Gibushon_Final_Model_Improved.pkl']
import pandas as pd
import statsmodels.api as sm

Evaluation_Center_Target = pd.DataFrame(merged_df, columns=["ID_Num", 'Predicted_Gibushon_Final_Grade', "Predicted_Gibushon_Grade"])
Evaluation_Center_Target.insert(0, 'const', 1)
import pandas as pd
import joblib

# Load the model from the file
Gibushon_Final_Grade_loaded_model = joblib.load('Gibushon_Final_Model_Improved.pkl')

# Assuming Evaluation_Center_Target is a DataFrame with "ID_Num" as the index column
# Drop the "ID_Num" column from the input data
Evaluation_Center_Target_without_index = Evaluation_Center_Target.drop('ID_Num', axis=1)

# Use the loaded model to make predictions on the new data
y_Gibushon_Final_Grade = Gibushon_Final_Grade_loaded_model.predict(Evaluation_Center_Target_without_index)

# Create a DataFrame with the predictions
df_gibushon_final_New = pd.DataFrame(y_Gibushon_Final_Grade, index=Evaluation_Center_Target.index, columns=['Gibushon_Final_Model_Improved'])

# Merge the "ID_Num" index variable back into the DataFrame
df_gibushon_final_New['ID_Num'] = Evaluation_Center_Target.ID_Num

# Save the DataFrame to a CSV file
df_gibushon_final_New.to_csv('predicted_grades_with_id.csv', index=False)

# Print df_gibushon_final DataFrame or use it as needed
df_gibushon_final_New
      Gibushon_Final_Model_Improved       ID_Num
0                          3.107213   37107588.0
1                          3.387140  211968169.0
2                          3.310372  340866375.0
3                          2.546464  206253106.0
4                          3.314058  310274717.0
...                             ...          ...
2244                       3.274339  318256278.0
2245                       1.667510   21939632.0
2246                       3.758979   39169396.0
2247                       3.968252   57501777.0
2248                       3.755766   32794695.0

[2249 rows x 2 columns]
Gibushon_Target - Prediction Improvment
Gibushon_Target = pd.DataFrame(merged_df, columns=["ID_Num", 'Predicted_Gibushon_Final_Grade', 'Predicted_Rama', "Predicted_Dapar", "Predicted_Hebrew", "Predicted_Normot", "Predicted_Personality_Diss", "Predicted_Gibushon_Grade", "Predicted_Gius_Result", 'Gibushon_Target'])

# Drop rows with missing values
Gibushon_Target.dropna(inplace=True)
import pandas as pd
import statsmodels.api as sm
from sklearn import linear_model

# Define predictors and response variable
x = Gibushon_Target[Gibushon_Target.columns[Gibushon_Target.columns.isin(["Predicted_Dapar", "Predicted_Gius_Result","Predicted_Gibushon_Grade"])]]
y = Gibushon_Target['Gibushon_Target']

# Add constant to the predictors
x = sm.add_constant(x)

# Create a linear regression model
regr = linear_model.LinearRegression()
regr.fit(x, y)

# Fit OLS regression model
model = sm.OLS(y, x).fit()

# Make predictions
Gibushon_Target['Gibushon_Target'] = model.predict(x)

# Print model summary and description
print_model = model.summary()
print("Model Summary:")
print(print_model)

# Print model description
print("\nModel Description:")
print("The model describes the relationship between the predicted Gibushon final grade and Gibushon grade, taking into account the constant term.")
Model Summary:
                            OLS Regression Results                            
==============================================================================
Dep. Variable:        Gibushon_Target   R-squared:                       0.333
Model:                            OLS   Adj. R-squared:                  0.322
Method:                 Least Squares   F-statistic:                     31.27
Date:                Tue, 09 Apr 2024   Prob (F-statistic):           1.91e-16
Time:                        16:13:25   Log-Likelihood:                -223.43
No. Observations:                 192   AIC:                             454.9
Df Residuals:                     188   BIC:                             467.9
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
============================================================================================
                               coef    std err          t      P>|t|      [0.025      0.975]
--------------------------------------------------------------------------------------------
const                       -0.6904      0.401     -1.722      0.087      -1.481       0.101
Predicted_Dapar              0.1113      0.061      1.832      0.068      -0.009       0.231
Predicted_Gibushon_Grade     0.9657      0.131      7.370      0.000       0.707       1.224
Predicted_Gius_Result        0.6991      0.384      1.823      0.070      -0.057       1.456
==============================================================================
Omnibus:                        2.872   Durbin-Watson:                   2.273
Prob(Omnibus):                  0.238   Jarque-Bera (JB):                2.625
Skew:                           0.285   Prob(JB):                        0.269
Kurtosis:                       3.065   Cond. No.                         44.2
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

Model Description:
The model describes the relationship between the predicted Gibushon final grade and Gibushon grade, taking into account the constant term.
from joblib import dump

# Save the model using joblib.dump
joblib.dump(model, 'Gibushon_Grade_Improved.pkl')
['Gibushon_Grade_Improved.pkl']
import pandas as pd
import statsmodels.api as sm

Gibushon_Target = pd.DataFrame(merged_df, columns=['ID_Num',"Predicted_Dapar", "Predicted_Gius_Result","Predicted_Gibushon_Grade"])
Gibushon_Target.insert(0, 'const', 1)
import pandas as pd
import joblib

# Load the model from the file
Gibushon_Grade_loaded_model = joblib.load('Gibushon_Grade_Improved.pkl')

# Assuming Evaluation_Center_Target is a DataFrame with "ID_Num" as the index column
# Drop the "ID_Num" column from the input data
Gibushon_Target_without_index = Gibushon_Target.drop('ID_Num', axis=1)

# Use the loaded model to make predictions on the new data
y_Gibushon_Final_Grade = Gibushon_Grade_loaded_model.predict(Gibushon_Target_without_index)

# Create a DataFrame with the predictions
df_gibushon_Grade_New = pd.DataFrame(y_Gibushon_Final_Grade, index=Gibushon_Target.index, columns=['Gibushon_Grade_Improved'])

# Merge the "ID_Num" index variable back into the DataFrame
df_gibushon_Grade_New['ID_Num'] = Gibushon_Target.ID_Num

# Save the DataFrame to a CSV file
df_gibushon_Grade_New.to_csv('predicted_grades_with_id.csv', index=False)

# Print df_gibushon_final DataFrame or use it as needed
df_gibushon_Grade_New
      Gibushon_Grade_Improved       ID_Num
0                    3.057018   37107588.0
1                    2.787854  211968169.0
2                    2.027121  340866375.0
3                    1.992218  206253106.0
4                    2.142329  310274717.0
...                       ...          ...
2244                 2.128634  318256278.0
2245                 1.272529   21939632.0
2246                 3.119544   39169396.0
2247                 3.375904   57501777.0
2248                 3.430760   32794695.0

[2249 rows x 2 columns]
Rama_Target - Prediction Improvment
RAMA_Target = pd.DataFrame(merged_df, columns=["ID_Num", 'Predicted_Gibushon_Final_Grade', 'Predicted_Rama', "Predicted_Dapar", "Predicted_Hebrew", "Predicted_Normot", "Predicted_Personality_Diss", "Predicted_Gibushon_Grade", "Predicted_Gius_Result", 'RAMA_Target'])

# Drop rows with missing values
RAMA_Target.dropna(inplace=True)
import pandas as pd
import statsmodels.api as sm
from sklearn import linear_model

# Define predictors and response variable
x = RAMA_Target[RAMA_Target.columns[RAMA_Target.columns.isin(["Predicted_Rama", "Predicted_Personality_Diss","Predicted_Gibushon_Grade"])]]
y = RAMA_Target['RAMA_Target']

# Add constant to the predictors
x = sm.add_constant(x)

# Create a linear regression model
regr = linear_model.LinearRegression()
regr.fit(x, y)

# Fit OLS regression model
model = sm.OLS(y, x).fit()

# Make predictions
RAMA_Target['RAMA_Target'] = model.predict(x)

# Print model summary and description
print_model = model.summary()
print("Model Summary:")
print(print_model)

# Print model description
print("\nModel Description:")
print("The model describes the relationship between the predicted Gibushon final grade and Gibushon grade, taking into account the constant term.")
Model Summary:
                            OLS Regression Results                            
==============================================================================
Dep. Variable:            RAMA_Target   R-squared:                       0.213
Model:                            OLS   Adj. R-squared:                  0.209
Method:                 Least Squares   F-statistic:                     60.17
Date:                Tue, 09 Apr 2024   Prob (F-statistic):           1.94e-34
Time:                        16:13:25   Log-Likelihood:                -663.14
No. Observations:                 672   AIC:                             1334.
Df Residuals:                     668   BIC:                             1352.
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
==============================================================================================
                                 coef    std err          t      P>|t|      [0.025      0.975]
----------------------------------------------------------------------------------------------
const                         -0.3950      0.348     -1.134      0.257      -1.079       0.289
Predicted_Rama                 0.9106      0.102      8.951      0.000       0.711       1.110
Predicted_Personality_Diss     0.5637      0.168      3.362      0.001       0.234       0.893
Predicted_Gibushon_Grade       0.2081      0.061      3.420      0.001       0.089       0.328
==============================================================================
Omnibus:                        9.095   Durbin-Watson:                   1.969
Prob(Omnibus):                  0.011   Jarque-Bera (JB):               11.539
Skew:                           0.153   Prob(JB):                      0.00312
Kurtosis:                       3.565   Cond. No.                         72.6
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

Model Description:
The model describes the relationship between the predicted Gibushon final grade and Gibushon grade, taking into account the constant term.
from joblib import dump

# Save the model using joblib.dump
joblib.dump(model, 'Rama_Model_Improved.pkl')
['Rama_Model_Improved.pkl']
import pandas as pd
import statsmodels.api as sm

Rama_Target = pd.DataFrame(merged_df, columns=['ID_Num',"Predicted_Rama", "Predicted_Personality_Diss","Predicted_Gibushon_Grade"])
Rama_Target.insert(0, 'const', 1)
import pandas as pd
import joblib

# Load the model from the file
Rama_Model_Improved = joblib.load('Rama_Model_Improved.pkl')

# Assuming Evaluation_Center_Target is a DataFrame with "ID_Num" as the index column
# Drop the "ID_Num" column from the input data
Rama_Target_without_index = Rama_Target.drop('ID_Num', axis=1)

# Use the loaded model to make predictions on the new data
y_Rama_Final_Grade = Rama_Model_Improved.predict(Rama_Target_without_index)

# Create a DataFrame with the predictions
df_Rama_Grade_New = pd.DataFrame(y_Rama_Final_Grade, index=Rama_Target.index, columns=['Rama_Model_Improved'])

# Merge the "ID_Num" index variable back into the DataFrame
df_Rama_Grade_New['ID_Num'] = Rama_Target.ID_Num

# Save the DataFrame to a CSV file
df_Rama_Grade_New.to_csv('predicted_grades_with_id.csv', index=False)

# Print df_gibushon_final DataFrame or use it as needed
df_Rama_Grade_New
      Rama_Model_Improved       ID_Num
0                4.544186   37107588.0
1                3.895517  211968169.0
2                4.175160  340866375.0
3                3.457134  206253106.0
4                3.516825  310274717.0
...                   ...          ...
2244             3.481318  318256278.0
2245             3.721314   21939632.0
2246             4.253590   39169396.0
2247             4.600385   57501777.0
2248             4.633158   32794695.0

[2249 rows x 2 columns]
Dapar_Target - Prediction Improvment
Dapar_Target = pd.DataFrame(merged_df, columns=["ID_Num", 'Predicted_Gibushon_Final_Grade', 'Predicted_Rama', "Predicted_Dapar", "Predicted_Hebrew", "Predicted_Normot", "Predicted_Personality_Diss", "Predicted_Gibushon_Grade", "Predicted_Gius_Result", 'Dapar_Target'])

# Drop rows with missing values
Dapar_Target.dropna(inplace=True)
import pandas as pd
import statsmodels.api as sm
from sklearn import linear_model

# Define predictors and response variable
x = Dapar_Target[Dapar_Target.columns[Dapar_Target.columns.isin(["Predicted_Dapar","Predicted_Gibushon_Grade"])]]
y = Dapar_Target['Dapar_Target']

# Add constant to the predictors
x = sm.add_constant(x)

# Create a linear regression model
regr = linear_model.LinearRegression()
regr.fit(x, y)

# Fit OLS regression model
model = sm.OLS(y, x).fit()

# Make predictions
Dapar_Target['Dapar_Target'] = model.predict(x)

# Print model summary and description
print_model = model.summary()
print("Model Summary:")
print(print_model)

# Print model description
print("\nModel Description:")
print("The model describes the relationship between the predicted Gibushon final grade and Gibushon grade, taking into account the constant term.")
Model Summary:
                            OLS Regression Results                            
==============================================================================
Dep. Variable:           Dapar_Target   R-squared:                       0.394
Model:                            OLS   Adj. R-squared:                  0.391
Method:                 Least Squares   F-statistic:                     151.8
Date:                Tue, 09 Apr 2024   Prob (F-statistic):           1.50e-51
Time:                        16:13:25   Log-Likelihood:                -825.81
No. Observations:                 471   AIC:                             1658.
Df Residuals:                     468   BIC:                             1670.
Df Model:                           2                                         
Covariance Type:            nonrobust                                         
============================================================================================
                               coef    std err          t      P>|t|      [0.025      0.975]
--------------------------------------------------------------------------------------------
const                       -0.6814      0.443     -1.539      0.124      -1.551       0.189
Predicted_Dapar              1.0229      0.064     15.927      0.000       0.897       1.149
Predicted_Gibushon_Grade     0.1786      0.145      1.231      0.219      -0.106       0.464
==============================================================================
Omnibus:                        3.525   Durbin-Watson:                   1.854
Prob(Omnibus):                  0.172   Jarque-Bera (JB):                3.051
Skew:                          -0.110   Prob(JB):                        0.217
Kurtosis:                       2.673   Cond. No.                         42.3
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

Model Description:
The model describes the relationship between the predicted Gibushon final grade and Gibushon grade, taking into account the constant term.
from joblib import dump

# Save the model using joblib.dump
joblib.dump(model, 'Dapar_Model_Improved.pkl')
['Dapar_Model_Improved.pkl']
import pandas as pd
import statsmodels.api as sm

Dapar_Target = pd.DataFrame(merged_df, columns=['ID_Num',"Predicted_Dapar","Predicted_Gibushon_Grade"])
Dapar_Target.insert(0, 'const', 1)
import pandas as pd
import joblib

# Load the model from the file
Dapar_Model_Improved = joblib.load('Dapar_Model_Improved.pkl')

# Assuming Evaluation_Center_Target is a DataFrame with "ID_Num" as the index column
# Drop the "ID_Num" column from the input data
Dapar_Target_without_index = Dapar_Target.drop('ID_Num', axis=1)

# Use the loaded model to make predictions on the new data
y_Dapar_Final_Grade = Dapar_Model_Improved.predict(Dapar_Target_without_index)

# Create a DataFrame with the predictions
df_Dapar_Grade_New = pd.DataFrame(y_Dapar_Final_Grade, index=Dapar_Target.index, columns=['Dapar_Model_Improved'])

# Merge the "ID_Num" index variable back into the DataFrame
df_Dapar_Grade_New['ID_Num'] = Dapar_Target.ID_Num

# Save the DataFrame to a CSV file
df_Dapar_Grade_New.to_csv('predicted_grades_with_id.csv', index=False)

# Print df_gibushon_final DataFrame or use it as needed
df_Dapar_Grade_New
      Dapar_Model_Improved       ID_Num
0                 8.494226   37107588.0
1                 5.740960  211968169.0
2                 4.567451  340866375.0
3                 3.565801  206253106.0
4                 4.822123  310274717.0
...                    ...          ...
2244              3.968185  318256278.0
2245              5.864237   21939632.0
2246              6.780521   39169396.0
2247              7.744939   57501777.0
2248              8.501701   32794695.0

[2249 rows x 2 columns]
Hebrew_Target - Prediction Improvment
Hebrew_Target = pd.DataFrame(merged_df, columns=["ID_Num", 'Predicted_Gibushon_Final_Grade', 'Predicted_Rama', "Predicted_Dapar", "Predicted_Hebrew", "Predicted_Normot", "Predicted_Personality_Diss", "Predicted_Gibushon_Grade", "Predicted_Gius_Result", 'Hebrew_Target'])

# Drop rows with missing values
Hebrew_Target.dropna(inplace=True)
import pandas as pd
import statsmodels.api as sm
from sklearn import linear_model

# Define predictors and response variable
x = Hebrew_Target[Hebrew_Target.columns[Hebrew_Target.columns.isin(["Predicted_Hebrew","Predicted_Normot", "Predicted_Gibushon_Grade"])]]
y = Hebrew_Target['Hebrew_Target']

# Add constant to the predictors
x = sm.add_constant(x)

# Create a linear regression model
regr = linear_model.LinearRegression()
regr.fit(x, y)

# Fit OLS regression model
model = sm.OLS(y, x).fit()

# Make predictions
Hebrew_Target['Hebrew_Target'] = model.predict(x)

# Print model summary and description
print_model = model.summary()
print("Model Summary:")
print(print_model)

# Print model description
print("\nModel Description:")
print("The model describes the relationship between the predicted Gibushon final grade and Gibushon grade, taking into account the constant term.")
Model Summary:
                            OLS Regression Results                            
==============================================================================
Dep. Variable:          Hebrew_Target   R-squared:                       0.456
Model:                            OLS   Adj. R-squared:                  0.452
Method:                 Least Squares   F-statistic:                     132.7
Date:                Tue, 09 Apr 2024   Prob (F-statistic):           1.72e-62
Time:                        16:13:25   Log-Likelihood:                -516.19
No. Observations:                 480   AIC:                             1040.
Df Residuals:                     476   BIC:                             1057.
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
============================================================================================
                               coef    std err          t      P>|t|      [0.025      0.975]
--------------------------------------------------------------------------------------------
const                        1.0407      0.577      1.804      0.072      -0.093       2.174
Predicted_Hebrew             0.8404      0.080     10.553      0.000       0.684       0.997
Predicted_Normot            -0.2372      0.042     -5.597      0.000      -0.320      -0.154
Predicted_Gibushon_Grade     0.1596      0.078      2.049      0.041       0.007       0.313
==============================================================================
Omnibus:                        1.850   Durbin-Watson:                   2.072
Prob(Omnibus):                  0.397   Jarque-Bera (JB):                1.783
Skew:                           0.019   Prob(JB):                        0.410
Kurtosis:                       3.296   Cond. No.                         146.
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

Model Description:
The model describes the relationship between the predicted Gibushon final grade and Gibushon grade, taking into account the constant term.
from joblib import dump

# Save the model using joblib.dump
joblib.dump(model, 'Hebrew_Model_Improved.pkl')
['Hebrew_Model_Improved.pkl']
import pandas as pd
import statsmodels.api as sm

Hebrew_Target = pd.DataFrame(merged_df, columns=['ID_Num',"Predicted_Hebrew","Predicted_Normot", "Predicted_Gibushon_Grade"])
Hebrew_Target.insert(0, 'const', 1)
import pandas as pd
import joblib

# Load the model from the file
Hebrew_Model_Improved = joblib.load('Hebrew_Model_Improved.pkl')

# Assuming Evaluation_Center_Target is a DataFrame with "ID_Num" as the index column
# Drop the "ID_Num" column from the input data
Hebrew_Target_without_index = Hebrew_Target.drop('ID_Num', axis=1)

# Use the loaded model to make predictions on the new data
y_Hebrew_Final_Grade = Hebrew_Model_Improved.predict(Hebrew_Target_without_index)

# Create a DataFrame with the predictions
df_Hebrew_Grade_New = pd.DataFrame(y_Hebrew_Final_Grade, index=Hebrew_Target.index, columns=['Hebrew_Model_Improved'])

# Merge the "ID_Num" index variable back into the DataFrame
df_Hebrew_Grade_New['ID_Num'] = Hebrew_Target.ID_Num

# Save the DataFrame to a CSV file
df_Hebrew_Grade_New.to_csv('predicted_grades_with_id.csv', index=False)

# Print df_gibushon_final DataFrame or use it as needed
df_Hebrew_Grade_New
      Hebrew_Model_Improved       ID_Num
0                  8.269838   37107588.0
1                  7.526553  211968169.0
2                  6.519356  340866375.0
3                  6.643841  206253106.0
4                  7.343707  310274717.0
...                     ...          ...
2244               7.154883  318256278.0
2245               6.028181   21939632.0
2246               8.423119   39169396.0
2247               8.264788   57501777.0
2248               8.667183   32794695.0

[2249 rows x 2 columns]
Normot_Target - Prediction Improvment
Normot_Target = pd.DataFrame(merged_df, columns=["ID_Num", 'Predicted_Gibushon_Final_Grade', 'Predicted_Rama', "Predicted_Dapar", "Predicted_Hebrew", "Predicted_Normot", "Predicted_Personality_Diss", "Predicted_Gibushon_Grade", "Predicted_Gius_Result", "Predicted_Evaluation_Center_Dico", "Yeodi_Liba", 'Normot_Target'])
Model Develop based on candidates for "yeodi liba" roles
import pandas as pd

# Assuming Normot_Sofi_Gold_List is your dataframe
# Assuming Yeodi_Liba is the variable/column in the dataframe

# Filter rows where Yeodi_Liba is not equal to 0
Normot_Target = Normot_Target[Normot_Target['Yeodi_Liba'] != 0]

# Reset index after dropping rows
Normot_Target.reset_index(drop=True, inplace=True)
Normot_Target.drop(columns=['Yeodi_Liba'], inplace=True)

# Drop rows with missing values
Normot_Target.dropna(inplace=True)
Normot Model Development
import pandas as pd
import statsmodels.api as sm
from sklearn import linear_model

# Define predictors and response variable
x = Normot_Target[Normot_Target.columns[Normot_Target.columns.isin(["Predicted_Normot", "Predicted_Gibushon_Grade"])]]
y = Normot_Target['Normot_Target']

# Add constant to the predictors
x = sm.add_constant(x)

# Create a linear regression model
regr = linear_model.LinearRegression()
regr.fit(x, y)

# Fit OLS regression model
model = sm.OLS(y, x).fit()

# Make predictions
Normot_Target['Normot_Target'] = model.predict(x)

# Print model summary and description
print_model = model.summary()
print("Model Summary:")
print(print_model)

# Print model description
print("\nModel Description:")
print("The model describes the relationship between the predicted Gibushon final grade and Gibushon grade, taking into account the constant term.")
Model Summary:
                            OLS Regression Results                            
==============================================================================
Dep. Variable:          Normot_Target   R-squared:                       0.203
Model:                            OLS   Adj. R-squared:                  0.196
Method:                 Least Squares   F-statistic:                     29.33
Date:                Tue, 09 Apr 2024   Prob (F-statistic):           4.52e-12
Time:                        16:13:26   Log-Likelihood:                -459.68
No. Observations:                 233   AIC:                             925.4
Df Residuals:                     230   BIC:                             935.7
Df Model:                           2                                         
Covariance Type:            nonrobust                                         
============================================================================================
                               coef    std err          t      P>|t|      [0.025      0.975]
--------------------------------------------------------------------------------------------
const                        1.3340      0.831      1.605      0.110      -0.303       2.971
Predicted_Normot             0.8912      0.133      6.692      0.000       0.629       1.154
Predicted_Gibushon_Grade    -0.4064      0.250     -1.625      0.106      -0.899       0.086
==============================================================================
Omnibus:                       63.210   Durbin-Watson:                   1.941
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              128.113
Skew:                           1.335   Prob(JB):                     1.52e-28
Kurtosis:                       5.463   Cond. No.                         26.4
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.

Model Description:
The model describes the relationship between the predicted Gibushon final grade and Gibushon grade, taking into account the constant term.
from joblib import dump

# Save the model using joblib.dump
joblib.dump(model, 'Normot_Model_Improved.pkl')
['Normot_Model_Improved.pkl']
import pandas as pd
import statsmodels.api as sm

Normot_Target = pd.DataFrame(merged_df, columns=['ID_Num','Predicted_Normot', "Predicted_Gibushon_Grade"])
Normot_Target.insert(0, 'const', 1)
Normot_Target
      const       ID_Num  Predicted_Normot  Predicted_Gibushon_Grade
0         1   37107588.0          0.658843                  3.032249
1         1  211968169.0          0.589567                  3.489384
2         1  340866375.0          1.925971                  3.044592
3         1  206253106.0          2.104191                  2.794325
4         1  310274717.0          0.866551                  3.250757
...     ...          ...               ...                       ...
2244      1  318256278.0          2.402527                  2.884404
2245      1   21939632.0          5.656580                  1.826283
2246      1   39169396.0          0.686932                  3.660230
2247      1   57501777.0          1.304140                  4.192437
2248      1   32794695.0          0.031614                  3.545976

[2249 rows x 4 columns]
import pandas as pd
import joblib

# Load the model from the file
Normot_Model_Improved = joblib.load('Normot_Model_Improved.pkl')

# Assuming Evaluation_Center_Target is a DataFrame with "ID_Num" as the index column
# Drop the "ID_Num" column from the input data
Normot_Target_without_index = Normot_Target.drop('ID_Num', axis=1)

# Use the loaded model to make predictions on the new data
y_Normot_Final_Grade = Normot_Model_Improved.predict(Normot_Target_without_index)

# Create a DataFrame with the predictions
df_Normot_Grade_New = pd.DataFrame(y_Normot_Final_Grade, index=Normot_Target.index, columns=['Normot_Model_Improved'])

# Merge the "ID_Num" index variable back into the DataFrame
df_Normot_Grade_New['ID_Num'] = Normot_Target.ID_Num

# Save the DataFrame to a CSV file
df_Normot_Grade_New.to_csv('predicted_grades_with_id.csv', index=False)

# Print df_gibushon_final DataFrame or use it as needed
df_Normot_Grade_New
      Normot_Model_Improved       ID_Num
0                  0.688696   37107588.0
1                  0.441165  211968169.0
2                  1.812893  340866375.0
3                  2.073432  206253106.0
4                  0.784988  310274717.0
...                     ...          ...
2244               2.302686  318256278.0
2245               5.632622   21939632.0
2246               0.458496   39169396.0
2247               0.792221   57501777.0
2248              -0.079061   32794695.0

[2249 rows x 2 columns]
Gius_Target - Prediction Improvment
Gius_Target = pd.DataFrame(merged_df, columns=["ID_Num", 'Predicted_Gibushon_Final_Grade', 'Predicted_Rama', "Predicted_Dapar", "Predicted_Hebrew", "Predicted_Normot", "Predicted_Gibushon_Grade", "Predicted_Gius_Result", "Gius_Target"])

# Drop rows with missing values
Gius_Target.dropna(inplace=True)
Gius_Target
           ID_Num  Predicted_Gibushon_Final_Grade  Predicted_Rama  \
1     211968169.0                        3.124436        3.885744   
2     340866375.0                        3.377852        3.923235   
3     206253106.0                        2.204261        3.519422   
4     310274717.0                        3.202141        3.500886   
5     315129197.0                        2.165717        3.929368   
...           ...                             ...             ...   
2221  318907649.0                        2.560572        4.003153   
2224  211301981.0                        2.440957        3.458399   
2225  316525831.0                        1.569345        3.551848   
2231  307898031.0                        3.569097        3.510909   
2242  316009851.0                        3.151195        3.128799   

      Predicted_Dapar  Predicted_Hebrew  Predicted_Normot  \
1            5.669301          7.221064          0.589567   
2            4.599727          6.484300          1.925971   
3            3.664198          6.730235          2.104191   
4            4.812698          7.126990          0.866551   
5            5.953427          7.549491          0.882854   
...               ...               ...               ...   
2221         5.584690          7.228233          1.304278   
2224         2.969674          6.395564          2.033012   
2225         4.510130          6.745985          2.713934   
2231         4.729149          6.362552          1.388478   
2242         5.291285          7.280334          0.346637   

      Predicted_Gibushon_Grade  Predicted_Gius_Result  Gius_Target  
1                     3.489384               0.422558          1.0  
2                     3.044592               0.080023          0.0  
3                     2.794325               0.332841          0.0  
4                     3.250757               0.025533          0.0  
5                     2.474724               0.314807          0.0  
...                        ...                    ...          ...  
2221                  2.625130               0.260491          1.0  
2224                  2.738124               0.246183          0.0  
2225                  2.115783               0.151508          0.0  
2231                  3.011424               0.081767          0.0  
2242                  2.981458               0.042963          0.0  

[549 rows x 9 columns]
import pandas as pd
import statsmodels.api as sm
from sklearn import linear_model

# Define predictors and response variable
x = Gius_Target[Gius_Target.columns[Gius_Target.columns.isin(["Predicted_Rama", "Predicted_Hebrew", "Predicted_Personality_Diss", "Predicted_Gius_Result"])]]
y = Gius_Target['Gius_Target']

# Add constant to the predictors
x = sm.add_constant(x)

# Create a logistic regression model
log_reg = linear_model.LogisticRegression()
log_reg.fit(x, y)

# Fit logistic regression model
model = sm.Logit(y, x).fit()

# Make predictions
Gius_Target['Predicted_Probability'] = model.predict(x)

# Print model summary
print_model = model.summary()
print("Model Summary:")
print(print_model)
Optimization terminated successfully.
         Current function value: 0.582205
         Iterations 6
Model Summary:
                           Logit Regression Results                           
==============================================================================
Dep. Variable:            Gius_Target   No. Observations:                  549
Model:                          Logit   Df Residuals:                      545
Method:                           MLE   Df Model:                            3
Date:                Tue, 09 Apr 2024   Pseudo R-squ.:                  0.1389
Time:                        16:13:26   Log-Likelihood:                -319.63
converged:                       True   LL-Null:                       -371.19
Covariance Type:            nonrobust   LLR p-value:                 3.303e-22
=========================================================================================
                            coef    std err          z      P>|z|      [0.025      0.975]
-----------------------------------------------------------------------------------------
const                    -3.4441      1.724     -1.998      0.046      -6.823      -0.066
Predicted_Rama            0.8282      0.437      1.894      0.058      -0.029       1.685
Predicted_Hebrew         -0.2850      0.202     -1.414      0.157      -0.680       0.110
Predicted_Gius_Result     5.0886      0.669      7.607      0.000       3.777       6.400
=========================================================================================
from joblib import dump

# Save the model using joblib.dump
joblib.dump(model, 'Gius_Results_Improved.pkl')
['Gius_Results_Improved.pkl']
import pandas as pd
import statsmodels.api as sm

Gius_Target = pd.DataFrame(merged_df, columns=['ID_Num',"Predicted_Rama", "Predicted_Hebrew", "Predicted_Gius_Result"])
Gius_Target.insert(0, 'const', 1)
import pandas as pd
import joblib

# Load the model from the file
Gius_Target_loaded_model = joblib.load('Gius_Results_Improved.pkl')

# Assuming Evaluation_Center_Target is a DataFrame with "ID_Num" as the index column
# Drop the "ID_Num" column from the input data
Gius_Target_without_index = Gius_Target.drop('ID_Num', axis=1)

# Use the loaded model to make predictions on the new data
y_Gius_Final_Grade = Gius_Target_loaded_model.predict(Gius_Target_without_index)

# Create a DataFrame with the predictions
df_gius_Grade_New = pd.DataFrame(y_Gius_Final_Grade, index=Gius_Target.index, columns=['Gius_Results_Improved'])

# Merge the "ID_Num" index variable back into the DataFrame
df_gius_Grade_New['ID_Num'] = Gius_Target.ID_Num

# Save the DataFrame to a CSV file
df_gius_Grade_New.to_csv('predicted_grades_with_id.csv', index=False)

# Print df_gibushon_final DataFrame or use it as needed
df_gius_Grade_New
      Gius_Results_Improved       ID_Num
0                  0.827512   37107588.0
1                  0.466486  211968169.0
2                  0.162982  340866375.0
3                  0.319897  206253106.0
4                  0.079699  310274717.0
...                     ...          ...
2244               0.319556  318256278.0
2245               0.086953   21939632.0
2246               0.594436   39169396.0
2247               0.386604   57501777.0
2248               0.854754   32794695.0

[2249 rows x 2 columns]
Personality_Dis_Safek_Target - Prediction Improvment
Personality_Dis_Safek_Target = pd.DataFrame(merged_df, columns=['ID_Num','Predicted_Gibushon_Final_Grade', 'Predicted_Rama', "Predicted_Dapar", "Predicted_Hebrew", "Predicted_Normot", "Predicted_Gibushon_Grade", "Predicted_Personality_Diss", "Predicted_Gius_Result", "Personality_Dis_Safek_Target"])

# Drop rows with missing values
Personality_Dis_Safek_Target.dropna(inplace=True)
import pandas as pd
import statsmodels.api as sm
from sklearn import linear_model

# Define predictors and response variable
x = Personality_Dis_Safek_Target[Personality_Dis_Safek_Target.columns[Personality_Dis_Safek_Target.columns.isin(["Predicted_Gibushon_Final_Grade", "Predicted_Normot", "Predicted_Personality_Diss"])]]
y = Personality_Dis_Safek_Target['Personality_Dis_Safek_Target']

# Add constant to the predictors
x = sm.add_constant(x)

# Create a logistic regression model
log_reg = linear_model.LogisticRegression()
log_reg.fit(x, y)

# Fit logistic regression model
model = sm.Logit(y, x).fit()

# Make predictions
Personality_Dis_Safek_Target['Predicted_Probability'] = model.predict(x)

# Print model summary
print_model = model.summary()
print("Model Summary:")
print(print_model)
Optimization terminated successfully.
         Current function value: 0.413927
         Iterations 6
Model Summary:
                                Logit Regression Results                                
========================================================================================
Dep. Variable:     Personality_Dis_Safek_Target   No. Observations:                  800
Model:                                    Logit   Df Residuals:                      796
Method:                                     MLE   Df Model:                            3
Date:                          Tue, 09 Apr 2024   Pseudo R-squ.:                  0.1111
Time:                                  16:13:26   Log-Likelihood:                -331.14
converged:                                 True   LL-Null:                       -372.53
Covariance Type:                      nonrobust   LLR p-value:                 7.804e-18
==================================================================================================
                                     coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------------
const                             -0.9389      0.722     -1.301      0.193      -2.353       0.476
Predicted_Gibushon_Final_Grade    -0.4414      0.198     -2.229      0.026      -0.830      -0.053
Predicted_Normot                  -0.2773      0.130     -2.139      0.032      -0.531      -0.023
Predicted_Personality_Diss         4.6511      0.600      7.752      0.000       3.475       5.827
==================================================================================================
from joblib import dump

# Save the model using joblib.dump
joblib.dump(model, 'Personality_Dis_Model_Improved.pkl')
['Personality_Dis_Model_Improved.pkl']
import pandas as pd
import statsmodels.api as sm

Personality_Dis_Safek_Target = pd.DataFrame(merged_df, columns=['ID_Num','Predicted_Personality_Diss', "Predicted_Gibushon_Final_Grade", "Predicted_Personality_Diss"])
Personality_Dis_Safek_Target.insert(0, 'const', 1)
import pandas as pd
import joblib

# Load the model from the file
Personality_Dis_Target_loaded_model = joblib.load('Personality_Dis_Model_Improved.pkl')

# Assuming Evaluation_Center_Target is a DataFrame with "ID_Num" as the index column
# Drop the "ID_Num" column from the input data
Personality_Dis_Target_without_index = Personality_Dis_Safek_Target.drop('ID_Num', axis=1)

# Use the loaded model to make predictions on the new data
y_Personality_Dis_Final_Grade = Personality_Dis_Target_loaded_model.predict(Personality_Dis_Target_without_index)

# Create a DataFrame with the predictions
df_Personality_Dis_New = pd.DataFrame(y_Personality_Dis_Final_Grade, index=Personality_Dis_Safek_Target.index, columns=['Personality_Dis_Model_Linear_Regression_New'])

# Merge the "ID_Num" index variable back into the DataFrame
df_Personality_Dis_New['ID_Num'] = Personality_Dis_Safek_Target.ID_Num

# Save the DataFrame to a CSV file
df_Personality_Dis_New.to_csv('predicted_grades_with_id.csv', index=False)

# Print df_gibushon_final DataFrame or use it as needed
df_Personality_Dis_New
      Personality_Dis_Model_Linear_Regression_New       ID_Num
0                                        0.452662   37107588.0
1                                        0.166524  211968169.0
2                                        0.699303  340866375.0
3                                        0.257713  206253106.0
4                                        0.186621  310274717.0
...                                           ...          ...
2244                                     0.172022  318256278.0
2245                                     0.767201   21939632.0
2246                                     0.162439   39169396.0
2247                                     0.147886   57501777.0
2248                                     0.162494   32794695.0

[2249 rows x 2 columns]
Evaluation Center Dico - Prediction Improvment
Final_Gibushon_Dico_Gold_List
           ID_Num  Predicted_Gibushon_Final_Grade  Predicted_Rama  \
2     340866375.0                        3.377852        3.923235   
3     206253106.0                        2.204261        3.519422   
4     310274717.0                        3.202141        3.500886   
19    208658179.0                        2.847203        4.117379   
21    322283128.0                        2.684544        3.803976   
...           ...                             ...             ...   
2112  211612924.0                        3.139516        4.133057   
2132  322659806.0                        2.937222        3.830343   
2186  213562432.0                        3.378558        4.293581   
2224  211301981.0                        2.440957        3.458399   
2225  316525831.0                        1.569345        3.551848   

      Predicted_Dapar  Predicted_Hebrew  Predicted_Gibushon_Grade  \
2            4.599727          6.484300                  3.044592   
3            3.664198          6.730235                  2.794325   
4            4.812698          7.126990                  3.250757   
19           6.761382          7.844248                  2.431049   
21           3.599754          7.016970                  2.552013   
...               ...               ...                       ...   
2112         4.472370          7.291395                  3.412866   
2132         4.540061          7.322234                  2.272798   
2186         4.692237          7.478305                  3.464836   
2224         2.969674          6.395564                  2.738124   
2225         4.510130          6.745985                  2.115783   

      Evaluation_Center_Dico_Target  
2                               0.0  
3                               1.0  
4                               0.0  
19                              0.0  
21                              1.0  
...                             ...  
2112                            1.0  
2132                            1.0  
2186                            1.0  
2224                            0.0  
2225                            0.0  

[193 rows x 7 columns]
Evaluation_Center_Dico_Target = pd.DataFrame(merged_df, columns=['ID_Num','Predicted_Gibushon_Final_Grade', 'Predicted_Rama', "Predicted_Dapar", "Predicted_Hebrew", "Predicted_Normot", "Predicted_Gibushon_Grade", "Predicted_Personality_Diss", "Predicted_Gius_Result", "Evaluation_Center_Dico_Target"])

# Drop rows with missing values
Evaluation_Center_Dico_Target.dropna(inplace=True)
import pandas as pd
import statsmodels.api as sm
from sklearn import linear_model

# Define predictors and response variable
x = Evaluation_Center_Dico_Target[Evaluation_Center_Dico_Target.columns[Evaluation_Center_Dico_Target.columns.isin(['Predicted_Gibushon_Grade', "Predicted_Hebrew"])]]
y = Evaluation_Center_Dico_Target['Evaluation_Center_Dico_Target']

# Add constant to the predictors
x = sm.add_constant(x)

# Create a logistic regression model
log_reg = linear_model.LogisticRegression()
log_reg.fit(x, y)

# Fit logistic regression model
model = sm.Logit(y, x).fit()

# Make predictions
Evaluation_Center_Dico_Target['Predicted_Probability'] = model.predict(x)

# Print model summary
print_model = model.summary()
print("Model Summary:")
print(print_model)
Optimization terminated successfully.
         Current function value: 0.574662
         Iterations 6
Model Summary:
                                 Logit Regression Results                                
=========================================================================================
Dep. Variable:     Evaluation_Center_Dico_Target   No. Observations:                  193
Model:                                     Logit   Df Residuals:                      190
Method:                                      MLE   Df Model:                            2
Date:                           Tue, 09 Apr 2024   Pseudo R-squ.:                  0.1638
Time:                                   16:13:26   Log-Likelihood:                -110.91
converged:                                  True   LL-Null:                       -132.63
Covariance Type:                       nonrobust   LLR p-value:                 3.680e-10
============================================================================================
                               coef    std err          z      P>|z|      [0.025      0.975]
--------------------------------------------------------------------------------------------
const                       -9.8880      2.561     -3.862      0.000     -14.907      -4.869
Predicted_Hebrew             0.4956      0.332      1.492      0.136      -0.155       1.147
Predicted_Gibushon_Grade     2.2292      0.440      5.062      0.000       1.366       3.092
============================================================================================
from joblib import dump

# Save the model using joblib.dump
joblib.dump(model, 'Final_Gibushon_Dico_Improved.pkl')
['Final_Gibushon_Dico_Improved.pkl']
import pandas as pd
import statsmodels.api as sm

Evaluation_Center_Dico_Target = pd.DataFrame(merged_df, columns=['ID_Num','Predicted_Hebrew', "Predicted_Gibushon_Grade"])
Evaluation_Center_Dico_Target.insert(0, 'const', 1)
import pandas as pd
import joblib

# Load the model from the file
Final_Gibushon_Dico_Target_loaded_model = joblib.load('Final_Gibushon_Dico_Improved.pkl')

# Assuming Evaluation_Center_Target is a DataFrame with "ID_Num" as the index column
# Drop the "ID_Num" column from the input data
Final_Gibushon_Dico_Target_without_index = Evaluation_Center_Dico_Target.drop('ID_Num', axis=1)

# Use the loaded model to make predictions on the new data
y_Final_Gibushon_Dico_Final_Grade = Final_Gibushon_Dico_Target_loaded_model.predict(Final_Gibushon_Dico_Target_without_index)

# Create a DataFrame with the predictions
df_Final_Gibushon_Dico_New = pd.DataFrame(y_Final_Gibushon_Dico_Final_Grade, index=Evaluation_Center_Dico_Target.index, columns=['Final_Gibushon_Dico_Improved'])

# Merge the "ID_Num" index variable back into the DataFrame
df_Final_Gibushon_Dico_New['ID_Num'] = Evaluation_Center_Dico_Target.ID_Num

# Save the DataFrame to a CSV file
df_Final_Gibushon_Dico_New.to_csv('predicted_grades_with_id.csv', index=False)

# Print df_gibushon_final DataFrame or use it as needed
df_Final_Gibushon_Dico_New
      Final_Gibushon_Dico_Improved       ID_Num
0                         0.719304   37107588.0
1                         0.812919  211968169.0
2                         0.528080  340866375.0
3                         0.419802  206253106.0
4                         0.708997  310274717.0
...                            ...          ...
2244                      0.552755  318256278.0
2245                      0.094780   21939632.0
2246                      0.914990   39169396.0
2247                      0.970842   57501777.0
2248                      0.898844   32794695.0

[2249 rows x 2 columns]
